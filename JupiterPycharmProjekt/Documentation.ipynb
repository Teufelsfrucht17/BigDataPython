{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"# Big Data Project\",\n",
    "   \"id\": \"1bf3680e1a6df4c9\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"## Main\",\n",
    "   \"id\": \"64dabb562aa9b3a9\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"import DataPrep\\n\",\n",
    "    \"import OLS_Regression\\n\",\n",
    "    \"import Ridge_Regression\\n\",\n",
    "    \"import SVR\\n\",\n",
    "    \"import NeuralNetworks\\n\",\n",
    "    \"import RandomForest\\n\",\n",
    "    \"import KNN\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(DataPrep.report)\\n\",\n",
    "    \"import DataPrep\\n\",\n",
    "    \"\\n\",\n",
    "    \"import JupiterPycharmProjekt.OLS_Regression\\n\",\n",
    "    \"import JupiterPycharmProjekt.Ridge_Regression\\n\",\n",
    "    \"import JupiterPycharmProjekt.SVR\\n\",\n",
    "    \"import JupiterPycharmProjekt.NeuralNetworks\\n\",\n",
    "    \"import JupiterPycharmProjekt.RandomForest\\n\",\n",
    "    \"import JupiterPycharmProjekt.KNN\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(DataPrep.report)\"\n",
    "   ],\n",
    "   \"id\": \"4aa6727a8fa07795\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This block executes all model training and evaluation scripts, collects their results and prints the final comparison report.\",\n",
    "   \"id\": \"e442bc24151843d4\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"## Data Preparation  gerne nochmal checken glaube haben dort einiges verändert\",\n",
    "   \"id\": \"b75501c1bdf61f70\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### General\\n\",\n",
    "    \"In this section the environment for Data Preparation is set up by importing essential Python libraries. Each library plays a key role for the Data Preparation.\"\n",
    "   ],\n",
    "   \"id\": \"f23b2b11019ed5c3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from matplotlib import pyplot as plt\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from sklearn import preprocessing\\n\",\n",
    "    \"from sklearn.preprocessing import LabelEncoder\\n\",\n",
    "    \"import numpy as np\"\n",
    "   ],\n",
    "   \"id\": \"3c8972a9db816a0d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"pandas:             Used for handling and analyzing structured data\\n\",\n",
    "    \"\\n\",\n",
    "    \"matplotlib.pyplot:  A fundamental plotting library.\\n\",\n",
    "    \"\\n\",\n",
    "    \"seaborn:            Built on top of matplotlib and simplifies the process of graphical statistics.\\n\",\n",
    "    \"\\n\",\n",
    "    \"sklearn.model_selection + train_test_split: Helps to split a dataset into training and test dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"sklearn.preprocessing + LabelEncoder: Transforming data before feeding it into a model.\\n\",\n",
    "    \"\\n\",\n",
    "    \"numpy: Is the foundational package for numerical computing in Python.\"\n",
    "   ],\n",
    "   \"id\": \"a05def101079fdb3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Read original data from CSV\",\n",
    "   \"id\": \"80b03ee3728e4444\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"data = pd.read_csv('UsedCarSellingPrices.csv')\",\n",
    "   \"id\": \"280e7d47459c1d19\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This code uses pandas to read the CSV file \\\"Used Car Selling Prices\\\" and loads it into a dataframe called 'data'.\",\n",
    "   \"id\": \"d1275f6a59584826\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Label-Encoding for Visualisation before cleaning\",\n",
    "   \"id\": \"3ca57ba84a5a98\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Define columns that need to be lable-encoded\",\n",
    "   \"id\": \"a9e48d7f80daa9de\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']\",\n",
    "   \"id\": \"647a721af1a27119\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This line defines a list of column names that represent categorical features in the dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"fuel: type of fuel that is used by the car\\n\",\n",
    "    \"\\n\",\n",
    "    \"seller_type: type of car seller\\n\",\n",
    "    \"\\n\",\n",
    "    \"transmission: type of gear\\n\",\n",
    "    \"\\n\",\n",
    "    \"owner: status of ownership\"\n",
    "   ],\n",
    "   \"id\": \"f9a160792dae95fc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Copy data into var label_encoded_data; create empty array lable_encoders\",\n",
    "   \"id\": \"f0568723c837ec\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"label_encoded_data = data.copy()\\n\",\n",
    "    \"label_encoders = {}\"\n",
    "   ],\n",
    "   \"id\": \"8cc316de039f21f3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This code sets up the environment for label encoding.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Line1: Copying the dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"Line2: Initializing the Encoders Dictionary\"\n",
    "   ],\n",
    "   \"id\": \"3f75c88b965669d5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Run lable-encoder for every previosly defined columne (function imported from sklearn)\",\n",
    "   \"id\": \"1515da396df78c06\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from sklearn.preprocessing import LabelEncoder\\n\",\n",
    "    \"for col in categorical_columns:\\n\",\n",
    "    \"    le = LabelEncoder()\\n\",\n",
    "    \"    label_encoded_data[col] = le.fit_transform(label_encoded_data[col])\\n\",\n",
    "    \"    label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nLabel-Encoded Data for Visualisation:\\\")\\n\",\n",
    "    \"print(label_encoded_data.head())\"\n",
    "   ],\n",
    "   \"id\": \"92396d934e28d479\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This loop iterates over each categorical column and applies Label Encoding transforming string labels into numeric codes.\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. for col in categorical_columns: Loops through each column listed earlier\\n\",\n",
    "    \"2. le = labelEncoder(): Creates a new LabelEncoder instance from scikit-learn for the current column\\n\",\n",
    "    \"3. label_encoded_data[col] = le.fit_transform(label_encoded_data[col]): Fits the encoder to the column's categories and transforms them into integers + Replaces the original text values in label_encoded_data with the corresponding numeric labels\\n\",\n",
    "    \"4. label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_))): Stores the mapping of original category names to their encoded values in the label_encoders dictionary + This allows to trace or reverse the encoding later if needed\"\n",
    "   ],\n",
    "   \"id\": \"9fecd8ff6cc49431\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### concatinates x and y into one point to be visualized\",\n",
    "   \"id\": \"dd4fb006cbf3b865\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"all_data_LableEncoded = pd.concat([label_encoded_data], axis=1)\",\n",
    "   \"id\": \"f375ebafb2613c84\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line creates a new DataFrame called 'all_data_LableEncoded' by concatenating 'label_encoded_data' along the column axis 'axis=1'\",\n",
    "   \"id\": \"a7984b3a89fbfec\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Drops all columes that are non-numeric to make scaling possible\",\n",
    "   \"id\": \"d39e31beaca0636e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"all_data_LableEncoded = all_data_LableEncoded.select_dtypes(include=['number'])\",\n",
    "   \"id\": \"9c96f2c72f3a5720\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line filters the dataset to keep only the numeric columns from 'all_data_LableEncoded'.\",\n",
    "   \"id\": \"eb9ddeb3e01426c4\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"#### Scale data (normalized via MinMaxScaler - between 0 and 1)\\n\",\n",
    "    \"sscaler = preprocessing.StandardScaler()    ???\\n\",\n",
    "    \"\\n\",\n",
    "    \"all_data_LableEncoded = sscaler.fit_transform(all_data_LableEncoded)    ???\"\n",
    "   ],\n",
    "   \"id\": \"9f12bd3a7f800f5d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"nscaler = preprocessing.MinMaxScaler()\\n\",\n",
    "    \"all_data_LableEncoded = nscaler.fit_transform(all_data_LableEncoded)\"\n",
    "   ],\n",
    "   \"id\": \"1a75a73ea660129a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block performs Min-Max Scaling on the numeric features in the dataset, transforming them into a commonscale between 0 and 1.\\n\",\n",
    "    \"1. Line1: Initalizes a MinMaxScaler object from scikit-learn\\n\",\n",
    "    \"2. Line2: Calculates the min and max values for each feature iin the dataset and applies the scaling transformation to each value\"\n",
    "   ],\n",
    "   \"id\": \"eae25a6e0d894e17\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Visualisation before cleaning Data\",\n",
    "   \"id\": \"4c2cc9b27675b657\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Reintegrates Column name for boxplot\",\n",
    "   \"id\": \"7e08f375a59ed8a0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"scaled_df = pd.DataFrame(all_data_LableEncoded, columns=label_encoded_data.select_dtypes(include='number').columns)\",\n",
    "   \"id\": \"5aff4042b4b9c951\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line converts the scaled NumPy array (from the Min-Max Scaler) back into a pandas DataFrame and restores the original column names.\",\n",
    "   \"id\": \"10bb9b3a7289d56f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Boxplot with readable x-axis\",\n",
    "   \"id\": \"612a72bd7c435c8b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"sns.boxplot(data=scaled_df, orient='v', palette='Set2')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.title(\\\"Normed boxplot\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"87c04c0b96869e27\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates a boxplot for each feature in the 'scaled_df' DataFrame to visualize the distribution and spread of the normalized (Min-max scaled) data.\\n\",\n",
    "    \"1. Line1: Sets the size of the figure to be 12 inches wide by 6 inches tall and ensures the plot is large enough to accommodate all features without crowding.\\n\",\n",
    "    \"2. Line2: Creates a vertical boxplot for each column in the 'scaled_df' DataFrame and uses Seaborn's elegant and color-friendly 'Set2' palette. Each box shows the median, the IQR and Whiskers & Outliers.\\n\",\n",
    "    \"3. Line3: Rotates the x-axis labels by 45 degrees for better readability, especially when there are many features.\\n\",\n",
    "    \"4. Line4: Adds a title to the plot for context, signaling that the data is normalized.\\n\",\n",
    "    \"5. Line5: Adjusts spacing to prevent overlap between axis labels, titles, and plot content.\\n\",\n",
    "    \"6. Line6: Renders and displays the final plot in the notebook.\"\n",
    "   ],\n",
    "   \"id\": \"ead6b42ead1e6a49\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Boxplot for only numerical data\",\n",
    "   \"id\": \"e0974975b2686d02\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"selected_cols = ['selling_price', 'km_driven', 'year']\\n\",\n",
    "    \"plt.figure(figsize=(8, 5))\\n\",\n",
    "    \"sns.boxplot(data=scaled_df[selected_cols], orient='v', palette='Set3')\\n\",\n",
    "    \"plt.title(\\\"Normed boxplot for numerical data only\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"a91e149b8d9268ef\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This blocks generates a boxplot visualization focused on three specific, scaled numerical features:\\n\",\n",
    "    \"\\n\",\n",
    "    \"'selling_price'\\n\",\n",
    "    \"\\n\",\n",
    "    \"'km_driven'\\n\",\n",
    "    \"\\n\",\n",
    "    \"'year'\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Line1: Selects the subset of important numerical features for focused analysis.\\n\",\n",
    "    \"2. Line2: Sets the plot size to be 8 inches wide and 5 inches tall.\\n\",\n",
    "    \"3. Line3: Creates a vertical boxplot for just the selected columns using the soft, pastel 'Set3' color palette from Seaborn.\\n\",\n",
    "    \"4. Line4: Adds a descriptive title to clarify that this plot shows normalized (scaled) numerical features.\\n\",\n",
    "    \"5. Line5: Ensures layout is adjusted for neatness and then displays the plot.\"\n",
    "   ],\n",
    "   \"id\": \"fb891a4313a2a18b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Pairplot to show correlation\",\n",
    "   \"id\": \"528da982deb168c1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"sns.pairplot(scaled_df[selected_cols])\\n\",\n",
    "    \"plt.suptitle(\\\"Pairplot for select charactaristics\\\", y=1.02)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"3cfc536eb1a2bc9c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This blocks creates a pairplot to visually explore pairwise relationships among the selected numerical features:\\n\",\n",
    "    \"\\n\",\n",
    "    \"'selling_price'\\n\",\n",
    "    \"\\n\",\n",
    "    \"'km_driven'\\n\",\n",
    "    \"\\n\",\n",
    "    \"'year'\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Line1: Creates a grid of scatterplots for each pairwise combination of the selected features. This helps to visualize Correlations, Clustering tendencies and Linearity or Non-Linearity Relationships. The Histograms are shown on the diagonal to represent each variable's distribution.\\n\",\n",
    "    \"2. Line2: Adds a super title above the entire plot grid.\\n\",\n",
    "    \"3. Line3: Renders the entire pairplot for viewing.\"\n",
    "   ],\n",
    "   \"id\": \"1f5e8aa1560acaa0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Clean Data & Create variable Brand\",\n",
    "   \"id\": \"65f778ecab77450\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Remove missing data\",\n",
    "   \"id\": \"4c8f6e7a09542f39\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"data = data.dropna()\",\n",
    "   \"id\": \"2478576eb668d23f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line removes all rows with missing values from the 'data' DataFrame.\",\n",
    "   \"id\": \"6cb30eeafdc41003\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Show how much data was removed\",\n",
    "   \"id\": \"9361739167ddf637\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"print(\\\"Data after removing data:\\\")\\n\",\n",
    "    \"print(data.isnull().sum())\\n\",\n",
    "    \"print(f\\\"Remaining rows: {len(data)}\\\")\"\n",
    "   ],\n",
    "   \"id\": \"4723ea92f78c504c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block checks and confirms that all missing values have been removed from the dataset and reports the number of remaining rows.\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Line1: Prints a header to indicate that the following output relates to the cleaned dataset.\\n\",\n",
    "    \"2. Line2: Checks for missing values in each column of the 'data' DataFrame, creates a Boolean mask of the same shape as the data and then counts the number of 'True' values in each column, i.e. the number of missing entries.\\n\",\n",
    "    \"3. Line3: Prints the total number of rows left in the dataset after dropping rows with missing values using 'len(data)'.\"\n",
    "   ],\n",
    "   \"id\": \"7320d64febbb147b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### IQR-based Removal of Outliers\",\n",
    "   \"id\": \"5e13c2d862a9c841\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"def remove_outliers_iqr(df, column):\\n\",\n",
    "    \"    Q1 = np.percentile(df[column], 25)\\n\",\n",
    "    \"    Q3 = np.percentile(df[column], 75)\\n\",\n",
    "    \"    IQR = Q3 - Q1\\n\",\n",
    "    \"    lower_bound = Q1 - 1.5 * IQR\\n\",\n",
    "    \"    upper_bound = Q3 + 1.5 * IQR\\n\",\n",
    "    \"    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\"\n",
    "   ],\n",
    "   \"id\": \"6c2d64ddee25c33f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This function removes outliers from a specific column in a DataFrame using the Interquartile Range (IQR) method\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. 'Q1': 25th percentile - the value below which 25% of the data falls\\n\",\n",
    "    \"2. 'Q3': 75th percentile - the value below which 75% of the data falls\\n\",\n",
    "    \"3. 'IQR = Q3-Q1': IQR is the spread of the middle 50% of values and it is used to understand the natural range of variation in the data.\\n\",\n",
    "    \"4. Line5 + Line6: These define the acceptable range and any values below the lower bound or above the upper bound are considered outliers.\\n\",\n",
    "    \"5. Line7: Returns a filtered version of the original DataFrame, keeping only the rows where the specified column's value is within the acceptable range -> Outlier are removed.\"\n",
    "   ],\n",
    "   \"id\": \"808fb431c2c8ca37\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Apply to most important column\",\n",
    "   \"id\": \"13bfcaa9e510db9c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"data = remove_outliers_iqr(data, 'selling_price')\\n\",\n",
    "    \"data = remove_outliers_iqr(data, 'km_driven')\"\n",
    "   ],\n",
    "   \"id\": \"bc179ef93d798956\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"These lines apply the IQR-based outlier removal function to two important columns in the dataset: 'selling_price' and 'km_driven'.\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Line1: Removes rows where 'selling_price' is considered an outlier based on the IQR rule and keeps only cars with selling prices within the typical range.\\n\",\n",
    "    \"2. Line2: Applies the same IQR filtering to the 'km_driven' column and eliminates unusually low or high mileage entries that could distort statistical analysis or model training.\"\n",
    "   ],\n",
    "   \"id\": \"8d99f03f1ca00747\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\nDaten nach IQR-basierter Ausreißerbereinigung:\\\")\\n\",\n",
    "    \"print(f\\\"Max. Verkaufspreis: {data['selling_price'].max()}\\\")\\n\",\n",
    "    \"print(f\\\"Max. Kilometerstand: {data['km_driven'].max()}\\\")\\n\",\n",
    "    \"print(f\\\"Verbleibende Zeilen nach IQR-Filter: {len(data)}\\\")\"\n",
    "   ],\n",
    "   \"id\": \"e8b00c4db8c02c69\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block prints a quick summary of the dataset after removing outliers using the IQR method.\\n\",\n",
    "    \"1. Line1: Prints a headline used for clarity when reading the console output.\\n\",\n",
    "    \"2. Line2: Displays the maximum selling price in the cleaned dataset which helps verifying that extremely high prices have been removed.\\n\",\n",
    "    \"3. Line3: Shows the maximum odometer reading after outlier removal and ensures that unusally high mileage values have been filtered out.\\n\",\n",
    "    \"4. Line4: Prints the number of remaining rows in the dataset which tells how much data is left after removing rows that contained outliers in 'selling_price' and 'km_driven'.\"\n",
    "   ],\n",
    "   \"id\": \"bab3eeed17c51636\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Create 'Brand' as new column\",\n",
    "   \"id\": \"7c3bf4ed9e5eac31\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"data['brand'] = data['name'].str.split().str[0]\\n\",\n",
    "    \"print(data)\"\n",
    "   ],\n",
    "   \"id\": \"1a35fe3e1026f49e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line creates a new column called 'brand' by extracting the first word from the 'name' column which represents the car brand.\",\n",
    "   \"id\": \"1edce02663cc2c28\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Label-Encoding for Visualisation after cleaning\",\n",
    "   \"id\": \"d7a160b07af3d056\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### ???\",\n",
    "   \"id\": \"9d58975c2852af76\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']\\n\",\n",
    "    \"label_encoded_data = data.copy()\\n\",\n",
    "    \"label_encoders = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for col in categorical_columns:\\n\",\n",
    "    \"    le = LabelEncoder()\\n\",\n",
    "    \"    label_encoded_data[col] = le.fit_transform(label_encoded_data[col])\\n\",\n",
    "    \"    label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nLabel-Encoded Data (nur zur Referenz):\\\")\\n\",\n",
    "    \"print(label_encoded_data.head())\"\n",
    "   ],\n",
    "   \"id\": \"2f3670cbf0cfa6df\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block performs label encoding on selected categorical columns, converting them from text values to integers so they can be used in regression models.\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Line1: Specifies the list of categorical features to be encoded which are typically textual descriptors that must be converted into numeric format for modeling.\\n\",\n",
    "    \"2. Line2: Creates a copy of the original dataset to apply the encodings without altering the raw data.\\n\",\n",
    "    \"3. Line3: Initializes an empty dictionary to store the encoding mappings for each categorical column.\\n\",\n",
    "    \"4. The 'for' loop: Iterates over each column in the 'categorical_columns' list; The 'LabelEncoder()' from scikit-learn is used to convert category labels into integers. The transformed values replace the original column in 'label_encoded_data'. The mapping of original class labels to integer codes is stored in 'label_encoders' for reference or inverse transformation later.\\n\",\n",
    "    \"5. Line10 + Line11: Displays the first few rows of the updated dataset to confirm that the categorical features have been encoded.\"\n",
    "   ],\n",
    "   \"id\": \"fad31c9e1922f96\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### concatinate x and y into one point to be visualized\",\n",
    "   \"id\": \"496f74c3b81afbcc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"all_data_LableEncoded = pd.concat([label_encoded_data], axis=1)\",\n",
    "   \"id\": \"90feb61d4cc86b9b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line creates a new DataFrame called 'all_data_LableEncoded' by concatenating the contents of 'label_encoded_data' along the columns axis.\",\n",
    "   \"id\": \"7f631765aeb1c740\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Drop all columns that are non-numeric to make scaling possible\",\n",
    "   \"id\": \"5a033f688a670b2a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"all_data_LableEncoded = all_data_LableEncoded.select_dtypes(include=['number'])\",\n",
    "   \"id\": \"534cde6690518511\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line filters the 'all_data_LableEncoded' DataFrame to include only numeric columns, removing any that are not numeric.\",\n",
    "   \"id\": \"9a3f1545a3b99ad3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"#### Scale data (normalized)\\n\",\n",
    "    \"\\n\",\n",
    "    \"sscaler = preprocessing.StandardScaler()\\n\",\n",
    "    \"\\n\",\n",
    "    \"all_data_LableEncoded = sscaler.fit_transform(all_data_LableEncoded)\"\n",
    "   ],\n",
    "   \"id\": \"4b07c06cb19fef75\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"nscaler = preprocessing.MinMaxScaler()\\n\",\n",
    "    \"all_data_LableEncoded = nscaler.fit_transform(all_data_LableEncoded)\"\n",
    "   ],\n",
    "   \"id\": \"ec105be81b324dc1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This code applies Min-Max Scaling to normalize all numeric features in the dataset, transforming their values to a common range between 0 and 1.\\n\",\n",
    "    \"1. Line1: Initializes a MinMaxScaler object from scikit-learn's 'preprocessing' module and will scale each feature individually.\\n\",\n",
    "    \"2. Line2: Calculates the minimum and maximum values for each feature and scales each value in the dataset to the 0-1 range.\"\n",
    "   ],\n",
    "   \"id\": \"2d24f8339d565fba\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Visualization after Data cleaning\",\n",
    "   \"id\": \"26e221dbf855a14d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Scale Data ???\",\n",
    "   \"id\": \"db27b50893bcf74b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"scaled_df = pd.DataFrame(all_data_LableEncoded, columns=label_encoded_data.select_dtypes(include='number').columns)\",\n",
    "   \"id\": \"45db41f2efeda0d2\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line converts the scaled NumPy array back into a pandas DataFrame and restores the original column names, making the data human-readable and easier to work with.\",\n",
    "   \"id\": \"1ba9c5d0affc2cc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 1. Boxplot with readable axis names\",\n",
    "   \"id\": \"46e216caa2154a2\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"sns.boxplot(data=scaled_df, orient='v', palette='Set2')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.title(\\\"Boxplot der skalierten numerischen Features\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"ba4be1f0e93359fa\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates a boxplot for all features in the 'scaled_df' DataFrame, which contains only scaled numeric data. The plot helps visually inspecting the distribution and variability of each feature.\\n\",\n",
    "    \"1. Line1: Sets the figure size to 12 inches wide by 6 inches tall for better readability.\\n\",\n",
    "    \"2. Line2: Uses Seaborn to draw vertical boxplots for each numeric feature in 'scaled_df' and 'palette=Set2' gives the plot a soft, color-coded appearance to distinguish features visually.\\n\",\n",
    "    \"3. Line3: Rotates the x-axis labels by 45 degrees so that long feature names dont overlap and remain legible.\\n\",\n",
    "    \"4. Line4: Adds a descriptive title\\n\",\n",
    "    \"5. Line5 + Line6: Adjusts the layout to avoid overlapping elements and displays the final plot.\"\n",
    "   ],\n",
    "   \"id\": \"8a94c98254259a59\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 2. Boxplot only for selected numeric columns\",\n",
    "   \"id\": \"e372e0ea45e7af3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"selected_cols = ['selling_price', 'km_driven', 'year']\\n\",\n",
    "    \"plt.figure(figsize=(8, 5))\\n\",\n",
    "    \"sns.boxplot(data=scaled_df[selected_cols], orient='v', palette='Set3')\\n\",\n",
    "    \"plt.title(\\\"Boxplot ausgewählter Merkmale\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"f572d28726daa6b1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates a boxplot visualization for a selected subset of key numeric features: 'selling_price', 'km_driven' and 'year', all of which have been previously scaled to 0-1 range.\\n\",\n",
    "    \"1. Line1: Selects the three features for targeted visualization.\\n\",\n",
    "    \"2. Line2: Sets the figure size to 8 inches wide and 5 inches tall for compact clarity.\\n\",\n",
    "    \"3. Line3: Draws vertical boxplots for just the selected columns using Seaborn's pastel 'Set3' color palette.\\n\",\n",
    "    \"4. Line4: Adds a title.\\n\",\n",
    "    \"5. Line5 + Line6: Adjusts spacing to prevent overlap and displays the plot.\"\n",
    "   ],\n",
    "   \"id\": \"d2798ae873fb6d6b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 3. Pairplot for Distribution and Correlation\",\n",
    "   \"id\": \"ae3ca5a17e95eb62\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"sns.pairplot(scaled_df[selected_cols])\\n\",\n",
    "    \"plt.suptitle(\\\"Paarweise Verteilungen ausgewählter Merkmale\\\", y=1.02)\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"#print(\\\"Trainingsdaten zusätzlich als 'prepared_used_car_data_train.parquet' gespeichert.\\\")\\n\",\n",
    "    \"#print(\\\"Testdaten zusätzlich als 'prepared_used_car_data_test.parquet' gespeichert.\\\")\\n\",\n",
    "    \"#print(\\\"Gesamtdaten zusätzlich als 'prepared_used_car_data.parquet' gespeichert.\\\")\"\n",
    "   ],\n",
    "   \"id\": \"c7d5546675dd85e8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates a pairplot that visualizes the pairwise relationships and distributions of three selected, scaled features: 'selling_price', 'km_driven' and 'year'.\\n\",\n",
    "    \"1. Line1: Generates a grid of plots: Scatter plots and Histograms.\\n\",\n",
    "    \"2. Line2: Adds a descriptive title above the plot grid; 'y=1.02' adjusts the title position slightly above the plot area to prevent overlap.\\n\",\n",
    "    \"3. Line3: Renders and displays the plot.\"\n",
    "   ],\n",
    "   \"id\": \"42e4cd0eb232d81c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### One-Hot-Encoding for Regression Model Training & Testing\",\n",
    "   \"id\": \"34beaaa83dfb659d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### One-Hot-Encoding for categorical Variables\",\n",
    "   \"id\": \"424611b424910f08\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"ncoded_data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nOne-Hot-Encoded Data:\\\")\\n\",\n",
    "    \"print(encoded_data.head())\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(encoded_data)\"\n",
    "   ],\n",
    "   \"id\": \"a3632ce25d57c669\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block uses one-hot encoding to transform categorical columns in the dataset into binary 0 or 1 columns, making them suitable for regression models.\\n\",\n",
    "    \"1. Line1: Performs one-hot encoding on the columns listed in 'categorical_columns'. For each unique category in these columns, new binary columns are created. Drops the first category for each column to avoid multicollinearity when using models like linear regression.\\n\",\n",
    "    \"2. Line3: Prints a header for clarity in console output.\\n\",\n",
    "    \"3. Line4: Displays the first few rows of the encoded dataset for a quick preview.\\n\",\n",
    "    \"4. Line6: Prints the entire DataFrame, which now contains both numeric and one-hot encoded binary columns.\"\n",
    "   ],\n",
    "   \"id\": \"61a0d41d69124fa9\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Sort data by 'year' and 'km_driven'\",\n",
    "   \"id\": \"86c04d61d9b69e1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"encoded_data_sorted = encoded_data.sort_values(by=['year', 'km_driven'], ascending=[False, True])\",\n",
    "   \"id\": \"a29562d18d8eab85\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line sorts the encoded dataset based on two columns - 'year' and 'km_driven' - to organize the data in a meaningful order.\",\n",
    "   \"id\": \"b5b2c20ee3fda993\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### Prepare data used for regression analysis\",\n",
    "   \"id\": \"f5c866911a853cd2\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"features = encoded_data_sorted.columns.drop(['name', 'selling_price'])\\n\",\n",
    "    \"target = 'selling_price'\\n\",\n",
    "    \"\\n\",\n",
    "    \"X = encoded_data_sorted[features]\\n\",\n",
    "    \"y = encoded_data_sorted[target]\"\n",
    "   ],\n",
    "   \"id\": \"7967234d07de09d7\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block prepares the feature matrix 'X' and target vector 'Y' for training a regression model, using sorted and one-hot encoded dataset.\\n\",\n",
    "    \"1. Line1: Selects all column names except: 'name' and 'selling_price' -> Result is a list of input features for the model.\\n\",\n",
    "    \"2. Line2: Explicitly defines 'selling_price' as the target variable.\\n\",\n",
    "    \"3. Line4: Creates the feature matrix 'X' by selecting only the columns in 'features' from the dataset; 'X' will be used as input for the regression model\\n\",\n",
    "    \"4. Line5: Creates the target vector 'Y', which contains the selling prices (values to be predicted)\"\n",
    "   ],\n",
    "   \"id\": \"a8b181cbc9a123a0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Saving test data\",\n",
    "   \"id\": \"a4bae775de587331\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"all_data = pd.concat([X, y], axis=1)\\n\",\n",
    "    \"all_data.to_csv('prepared_used_car_data_all.csv', index=False)\"\n",
    "   ],\n",
    "   \"id\": \"1487581c01f6a249\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block recombines the feature 'X' and target 'Y' into a single DataFrame and saves it as a '.csv' file for future use.\\n\",\n",
    "    \"1. Line1: Concatenates the feature matrix 'X' and the target vector 'Y' horizontally and reconstructs the full dataset 'all_data' with both inputs and outputs in one table.\\n\",\n",
    "    \"2. Line2: Saves the combined dataset to a CSV file and ensures that the DataFrame index is not written to the file, keeping the output clean and suitable for reuse.\"\n",
    "   ],\n",
    "   \"id\": \"ce5595b313fc27d5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Creation of training and test data\",\n",
    "   \"id\": \"be0ae433862329da\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\",\n",
    "   \"id\": \"532c67feaf5f924f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line uses scikit-learn's 'train_test_split()' function to divide the dataset into training and testing subsets, a crucial step for evaluating regression models.\",\n",
    "   \"id\": \"1d5e917ccd7fedec\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Saving of training data\",\n",
    "   \"id\": \"d658474144423a97\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"train_data = pd.concat([X_train, y_train], axis=1)\\n\",\n",
    "    \"train_data.to_csv('prepared_used_car_data_train.csv', index=False)\"\n",
    "   ],\n",
    "   \"id\": \"a1134ca92ea2ee04\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block combines the training features and labels into a single DataFrame and then exports it to a '.csv' file for storage or reuse.\\n\",\n",
    "    \"1. Line1: Merges the training input features 'X_train' and then training target values 'Y_train' side by side (along columns) and produces a single DataFrame 'train_data' that contains all the necessary data for training a model.\\n\",\n",
    "    \"2. Line2: Saves the 'train_data' DataFrame as a CSV file and ensures the row indices are not written into the file, keeping it clean and easy to reload.\"\n",
    "   ],\n",
    "   \"id\": \"b5b767072458240\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Saving of test data\",\n",
    "   \"id\": \"8ae9c1209c27c6b8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"test_data = pd.concat([X_test, y_test], axis=1)\\n\",\n",
    "    \"test_data.to_csv('prepared_used_car_data_test.csv', index=False)\"\n",
    "   ],\n",
    "   \"id\": \"f5ecb1a8e5800d0c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This code combines the test features and labels into a single DataFrame and then saves it as a CSV file for future use or evaluation.\\n\",\n",
    "    \"1. Line1: Merges the test feature set 'X_test' and the corresponding target values 'Y_test' horizontally and produces a new DataFrame 'test_data' that includes all the columns needed to evaluate a regression model.\\n\",\n",
    "    \"2. Line2: Saves the resulting test dataset to a CSV file and prevents the row index from being included in the file, making the CSV clean and readable.\"\n",
    "   ],\n",
    "   \"id\": \"b417829164c3d2d9\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Confirming saved files\",\n",
    "   \"id\": \"b53fcc1b31f27a5f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\nTrainingsdaten gespeichert als 'prepared_used_car_data_train.csv'\\\")\\n\",\n",
    "    \"print(\\\"Testdaten gespeichert als 'prepared_used_car_data_test.csv'\\\")\"\n",
    "   ],\n",
    "   \"id\": \"144ab05b37ea8757\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"These print statements simply confirm to the user that the training and test datasets have been successfully saved to CSV files.\\n\",\n",
    "    \"1. Line1: Outputs a message confirming that the training data was saved.\\n\",\n",
    "    \"2. Line2: Confirms that the test data was also saved.\"\n",
    "   ],\n",
    "   \"id\": \"e728efe85e240e7f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"## KNN\",\n",
    "   \"id\": \"913fdd0c6b08df1f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Set Up\",\n",
    "   \"id\": \"ef36d85c8da1450c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from sklearn.neighbors import KNeighborsRegressor\\n\",\n",
    "    \"from sklearn.model_selection import GridSearchCV, train_test_split\\n\",\n",
    "    \"import DataPrep\\n\",\n",
    "    \"\\n\",\n",
    "    \"(X_train_KNN, X_test_KNN, Y_train_KNN, Y_test_KNN) = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)\"\n",
    "   ],\n",
    "   \"id\": \"511b1e9da195258b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block sets upo the environment to train and evaluate a K-Nearest Neighbors Regression model using a train/test split of preprocessed data.\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Line1: Imports the KNN regressor from scikit-learn\\n\",\n",
    "    \"2. Line2: Adds a tool for hyperparameter tuning by trying different values and splits the dataset into training and testing sets\\n\",\n",
    "    \"3. Line3: Imports the DataPrep file\\n\",\n",
    "    \"4. Line5: Splits features and target into a training set and testing set while ensuring that the split is reproducible\"\n",
    "   ],\n",
    "   \"id\": \"88890b73da1c3e46\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Initialize KNN model\",\n",
    "   \"id\": \"96f94c4c912cc921\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"knnmodelCV = KNeighborsRegressor()\",\n",
    "   \"id\": \"2294d053ab7fc4a0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line creates an instance of the KNN model from scikit-learn with default parameters.\",\n",
    "   \"id\": \"87886d8e6cbaffdc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Define grid of neighbor counts\",\n",
    "   \"id\": \"7565349b274051ba\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"param_grid = {\\n\",\n",
    "    \"'n_neighbors': range(3, 22, 2),\\n\",\n",
    "    \"'weights': ['uniform', 'distance'],\\n\",\n",
    "    \"'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\\n\",\n",
    "    \"'leaf_size': [8, 16, 32, 64, 128, 256, 512],\\n\",\n",
    "    \"'p': [2, 3, 4, 5, 6, 7, 8]\\n\",\n",
    "    \"\\n\",\n",
    "    \"}\"\n",
    "   ],\n",
    "   \"id\": \"1ac6f8cb0f3ca853\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block defines a hyperparameter grid that will be used to tune a KNN regressor using tools like GridSearchCV.\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Line2: Tries odd values for k from 3 to 21 which defines how many neighbors the model considers when making predictions.\\n\",\n",
    "    \"2. Line3: 'uniform' makes sure all neighbors contribute equally to the prediction and 'distance' makes sure that closer neighbors contribute more to the prediction than distant ones.\\n\",\n",
    "    \"3. Line4: Specifies the search algorithm used to find neighbors. 'auto' -> Chooses the best algorithm based on the data. 'ball_tree' and 'kd_tree' -> Use tree structure for fast searches. 'brute' -> Calculates distances directly.\\n\",\n",
    "    \"4. Line5: Affects the speed vs. memory tradeoff in tree based algorithms. Smaller values result in faster query time. Larger values result in faster tree building.\\n\",\n",
    "    \"5. Line6: Specifies the power parameter for the Minkowski distance.\"\n",
    "   ],\n",
    "   \"id\": \"9fa17ca71204c291\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Run 10-fold cross-validation across neighbor settings\",\n",
    "   \"id\": \"6dcc98717ded8420\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"CV_knnmodel = GridSearchCV(estimator=knnmodelCV, param_grid=param_grid, cv=10,n_jobs=-1)\\n\",\n",
    "    \"CV_knnmodel.fit(X_train_KNN, Y_train_KNN)\"\n",
    "   ],\n",
    "   \"id\": \"982ed5930d7a7c0f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This code uses GridSearchCV from scikit-learn to perform an exhaustive search over a defined set of hyperparameters for a KNN regression model.\\n\",\n",
    "    \"Assigns all available CPU cores to parallelize the search and speed up computation and uses 10-fold cross-validation.\"\n",
    "   ],\n",
    "   \"id\": \"8e884a5c287dd7b7\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Output the best number of neighbors\",\n",
    "   \"id\": \"68d7a16cecfb1ef\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"print(\\\"Best parameters found:\\\", CV_knnmodel.best_params_)\",\n",
    "   \"id\": \"ab08d576e3bc342c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line prints the optimal set of hyperparameters that were found during the GridSearchCV process.\",\n",
    "   \"id\": \"23271a575ac5ca71\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Evaluating Model Performance\",\n",
    "   \"id\": \"77ba83f7b6489e0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_train_pred = CV_knnmodel.predict(X_train_KNN)\\n\",\n",
    "    \"Y_train_dev = sum((Y_train_KNN - Y_train_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_train_KNN - Y_train_KNN.mean())**2)\\n\",\n",
    "    \"r2 = 1 - Y_train_dev / Y_train_meandev\"\n",
    "   ],\n",
    "   \"id\": \"474d1ff7e08dbfa5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block manually calculates the coefficient of determination (r2) to evaluate how well the KNN model fits the training data.\\n\",\n",
    "    \"1. Line1: Uses the trained cross-validated KNN model to predict selling prices for the training set.\\n\",\n",
    "    \"2. Line2: Calculates the residual sum of squares (RSS) and measures how far off the predictions are from the actual values which should be minimal.\\n\",\n",
    "    \"3. Line3: Calculates the total sum of squares (TSS) and measures the total variation in the target variable (how far are values from the mean)\\n\",\n",
    "    \"4. Line4: Calculates the coefficient of determination (r2).\"\n",
    "   ],\n",
    "   \"id\": \"3cad2e436bf95347\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Predict on test set\",\n",
    "   \"id\": \"2bfe85c50a2cfb01\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_test_pred = CV_knnmodel.predict(X_test_KNN)\\n\",\n",
    "    \"Y_test_dev = sum((Y_test_KNN - Y_test_pred)**2)\\n\",\n",
    "    \"Y_test_meandev = sum((Y_test_KNN - Y_test_KNN.mean())**2)\\n\",\n",
    "    \"pseudor2 = 1 - Y_test_dev / Y_test_meandev\\n\",\n",
    "    \"\\n\",\n",
    "    \"DataPrep.report.loc[len(DataPrep.report)] = [\\\"KNN_LE \\\", r2, pseudor2,\\\"\\\", CV_knnmodel.cv_results_['mean_test_score'][CV_knnmodel.best_index_], CV_knnmodel.cv_results_['std_test_score'][CV_knnmodel.best_index_]]\"\n",
    "   ],\n",
    "   \"id\": \"63c9f4fdd36f8ca2\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block evaluates the KNN model on the test set using the coefficient of determination and calculates a pseudo r2 score for generalization performance and appends a summary row to report DataFrame for later comparison with other models.\\n\",\n",
    "    \"1. Line1: Uses the best tuned KNN model to predict the selling prices for the test set.\\n\",\n",
    "    \"2. Line2: Calculates the residual sum of squares (RSS) on the test data.\\n\",\n",
    "    \"3. Line3: Computes the total sum of squares (TSS) of the actual test values\\n\",\n",
    "    \"4. Line4: Calculates pseudo-r2 which is the models explanatory power on the unseen test data.\\n\",\n",
    "    \"5. Line6: Logs results to a report.\"\n",
    "   ],\n",
    "   \"id\": \"a9353e03545b53f1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Splitting One-Hot Encoded Data for Training and Testing\",\n",
    "   \"id\": \"1c32ccb1e13d0a21\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"X_train_KNN, X_test_KNN, Y_train_KNN, Y_test_KNN) = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)\",\n",
    "   \"id\": \"83765b9d7b1f833b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line splits the one-hot encoded dataset into training and testing sets for building and evaluating a KNN model.\",\n",
    "   \"id\": \"583ba6eca30b9ed3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Run 10-fold cross-validation across neighbor settings\",\n",
    "   \"id\": \"ca064ee8b924495d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"CV_knnmodel = GridSearchCV(estimator=knnmodelCV, param_grid=param_grid, cv=10,n_jobs=-1)\\n\",\n",
    "    \"CV_knnmodel.fit(X_train_KNN, Y_train_KNN)\"\n",
    "   ],\n",
    "   \"id\": \"aeb112676327e6be\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block performs hyperparameter optimization for the KNN regression model using one-hot encoded data with cross validation to ensure reliable model selection.\\n\",\n",
    "    \"1. Line1: Performs an exhaustive grid search over the parameter combinations defined in 'param_grid'.\\n\",\n",
    "    \"2. Line2: Trains and evaluates all hyperparameter combinations using the training data based on one-hot encoded features.\"\n",
    "   ],\n",
    "   \"id\": \"582037eb7717b901\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Output the best number of neighbors\",\n",
    "   \"id\": \"df30201764aec89c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"print(\\\"Best parameters found:\\\", CV_knnmodel.best_params_)\\n\",\n",
    "    \"Y_train_pred = CV_knnmodel.predict(X_train_KNN)\\n\",\n",
    "    \"Y_train_dev = sum((Y_train_KNN - Y_train_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_train_KNN - Y_train_KNN.mean())**2)\\n\",\n",
    "    \"r2 = 1 - Y_train_dev / Y_train_meandev\"\n",
    "   ],\n",
    "   \"id\": \"6e43f95c135b9312\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This line prints the optimal hyperparameter combination selected by 'GridSearchCV' for the KNN regression model trained on one-hot encoded data.\\n\",\n",
    "    \"1. Line2: Predicts the selling prices for the training data using the best-found KNN model.\\n\",\n",
    "    \"2. Line3: Computes the residual sum of squares (RSS) and measures how much error remains after using the models predictions.\\n\",\n",
    "    \"3. Line4: Computes the total sum of squares (TSS) and represents the total variance in the training labels serving as a baseline.\\n\",\n",
    "    \"4. Line5: Calculates the r2 score which explains how much variation is explained by the model.\"\n",
    "   ],\n",
    "   \"id\": \"831cd79491d672da\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Predict on test set\",\n",
    "   \"id\": \"3432bff5642ee100\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_test_pred = CV_knnmodel.predict(X_test_KNN)\\n\",\n",
    "    \"Y_test_dev = sum((Y_test_KNN - Y_test_pred)**2)\\n\",\n",
    "    \"Y_test_meandev = sum((Y_test_KNN - Y_test_KNN.mean())**2)\\n\",\n",
    "    \"pseudor2 = 1 - Y_test_dev / Y_test_meandev\"\n",
    "   ],\n",
    "   \"id\": \"eb5880e8f8375013\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block evaluates how well the tuned KNN model generalizes to unseen data by manually calculating the pseudo r2 score.\\n\",\n",
    "    \"1. Line1: Uses the trained KNN model to predict selling prices for the test set.\\n\",\n",
    "    \"2. Line2: Computes the residual sum of squares (RSS) for the test set and measures the models prediction error on unseen data.\\n\",\n",
    "    \"3. Line3: Compues the total sum of squares (TSS) for the test set and represents the total variance in the actual test values serving as a baseline.\\n\",\n",
    "    \"4. Line4: Calculates the pseudo-r2 and indicates how well the model generalizes to new unseen data.\"\n",
    "   ],\n",
    "   \"id\": \"1b6128865347c811\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Log KNN Model results in a report\",\n",
    "   \"id\": \"db8277422d3a75cb\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"DataPrep.report.loc[len(DataPrep.report)] = [\\\"KNN_OH \\\", r2, pseudor2,\\\"\\\", CV_knnmodel.cv_results_['mean_test_score'][CV_knnmodel.best_index_], CV_knnmodel.cv_results_['std_test_score'][CV_knnmodel.best_index_]]\\n\",\n",
    "    \"print(DataPrep.report.head())\\n\",\n",
    "    \"print(CV_knnmodel.best_params_)\"\n",
    "   ],\n",
    "   \"id\": \"3661288c5440411b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This block logs the performance metrics of the KNN model trained with one-hot encoded data into a centralized evaluation report and then displays the report and the best hyperparameters.\",\n",
    "   \"id\": \"fd8549bb992fcc71\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"## Neural Networks\",\n",
    "   \"id\": \"c0298822913ab143\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Preparation to train a Neural Network\",\n",
    "   \"id\": \"2459a43857effd0f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from sklearn.model_selection import train_test_split, GridSearchCV\\n\",\n",
    "    \"from sklearn.neural_network import MLPRegressor\\n\",\n",
    "    \"import DataPrep\"\n",
    "   ],\n",
    "   \"id\": \"d1a96d3bda5b49bd\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block sets up the environment for training and tuning a neural network regression model using scikit-learn's 'MLPRegressor' with data and configuration coming from a shared module called 'DataPrep'.\\n\",\n",
    "    \"1. Line1: Used to split data into training and testing sets and enables hyperparameter tuning using exhaustive search with cross-validation.\\n\",\n",
    "    \"2. Line2: Imports 'MLPRegressor' a multilayer perceptron for regression tasks.\\n\",\n",
    "    \"3. Line3: Imports the 'DataPrep' module.\"\n",
    "   ],\n",
    "   \"id\": \"ea18a40661d12073\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Splitting Label-Encoded Data\",\n",
    "   \"id\": \"83ff98b11f54bde9\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"(X_train_nn, X_test_nn, Y_train_nn, Y_test_nn) = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)\",\n",
    "   \"id\": \"ed26efe58f08b64e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line splits the label-encoded dataset into training and testing sets preparing it for use in training a neural network regression model.\",\n",
    "   \"id\": \"938be294c034fd3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Defining a Hyperparameter Grid for Tuning the Network Regressor\",\n",
    "   \"id\": \"8cfbc2704d7e93e0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"param_grid = {\\n\",\n",
    "    \"'hidden_layer_sizes': [(5,), (8,), (10,), (13,)],\\n\",\n",
    "    \"'alpha': [0.0, 0.0025, 0.005, 0.0075, 0.01, 0.1],\\n\",\n",
    "    \"'activation': ['logistic', 'tanh', 'relu'],\\n\",\n",
    "    \"'solver': ['sgd', 'adam', 'lbfgs'],\\n\",\n",
    "    \"'max_iter': [5000],\\n\",\n",
    "    \"'random_state': [0],\\n\",\n",
    "    \"'learning_rate': ['constant', 'invscaling', 'adaptive'],\\n\",\n",
    "    \"}\"\n",
    "   ],\n",
    "   \"id\": \"11c13350df76b1fb\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block defines a parameter grid to be used with 'GridSearchCV' for tuning a 'MLPRegressor' model in a regression task. Each key represents a hyperparameter and each value is a list of options that 'GridSearchCV' will explore during cross-validation.\\n\",\n",
    "    \"1. Line2: Defines the structure of the hidden layers; how many neurons\\n\",\n",
    "    \"2. Line3: L2 regularization term which helps to prevent overfitting by penalizing large weights\\n\",\n",
    "    \"3. Line4: Specifies the activation function used in the hidden layers\\n\",\n",
    "    \"4. Line5: Optimization algorithm used for training\\n\",\n",
    "    \"5. Line6: Sets the maximum number of training iterations to 5000\\n\",\n",
    "    \"6. Line7: Ensures reproducibility by fixing the random seed used inernally by the model\\n\",\n",
    "    \"6. Line8: Controls how the learning rate adapts over time when using 'sgd' or 'adam'\"\n",
    "   ],\n",
    "   \"id\": \"c2a8259638519a2e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Training a Neural Network with Grid Search and Cross-Validation\",\n",
    "   \"id\": \"3b317525d6e67e84\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"NNetRregCV = MLPRegressor()\\n\",\n",
    "    \"CV_nnmodel = GridSearchCV(estimator=NNetRregCV, param_grid=param_grid, cv=10,n_jobs=-1)\\n\",\n",
    "    \"CV_nnmodel.fit(X_train_nn, Y_train_nn)\"\n",
    "   ],\n",
    "   \"id\": \"e0102299ad7865d0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates, tunes and trains a neural network regressor using scikit-learn's 'MLPRegressor' and 'GridSearchCV'.\\n\",\n",
    "    \"1. Line1: Initializes a Multi-Layer Perceptron (MLP) Regressor which is a type of feedforward neural network.\\n\",\n",
    "    \"2. Line2: Wraps the neural network model with 'GridSearchCV' to perform automated hyperparameter tuning.\\n\",\n",
    "    \"3. Line3: Trains the model using the training data and runs the grid search.\"\n",
    "   ],\n",
    "   \"id\": \"ed941239c09b3d13\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Evaluating the Neural Network on Training Data\",\n",
    "   \"id\": \"15928d9333a02d79\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_train_pred = CV_nnmodel.predict(X_train_nn)\\n\",\n",
    "    \"Y_train_dev = sum((Y_train_nn - Y_train_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_train_nn - Y_train_nn.mean())**2)  # [aus PDF]\\n\",\n",
    "    \"r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]\"\n",
    "   ],\n",
    "   \"id\": \"6c478d8829a7dc0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block manually calculates the r2 score to evaluate how well the trained neural network model fits the training data.\\n\",\n",
    "    \"1. Line1: Uses the best neural network model selected by 'GridSearchCV' to predict target values for the training set\\n\",\n",
    "    \"2. Line2: Calculates the residual sum of squares (RSS) and measures the total prediction error of the model\\n\",\n",
    "    \"3. Line3: Calculates the total sum of squares (TSS) and measures how much variance is in the target data without any model\\n\",\n",
    "    \"4. Line4: Computes the r2 score which explains the variance in the training data\"\n",
    "   ],\n",
    "   \"id\": \"6223243634634b44\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Evaluating the Neural Network on Test Data\",\n",
    "   \"id\": \"2d660e23601c4437\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_test_pred = CV_nnmodel.predict(X_test_nn)\\n\",\n",
    "    \"Y_test_dev = sum((Y_test_nn - Y_test_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_test_nn - Y_test_nn.mean())**2)  # [aus PDF]\\n\",\n",
    "    \"pseudor2 = 1 - Y_test_dev / Y_train_meandev\"\n",
    "   ],\n",
    "   \"id\": \"aebea710b755b8c6\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block calculates the pseudo r2 score to assess how well the trained neural network regressor performs on unseen test data.\\n\",\n",
    "    \"1. Line1: Predicts target values for the test set using the neural network model selected by 'GridSearchCV'\\n\",\n",
    "    \"2. Line2: Computes the residual sum of squares (RSS) for the test set which represents the total prediction error of the model on unseen data\\n\",\n",
    "    \"3. Line3: Computes the total sum of squares (TSS) for the test set which represents the total variance in the target values\\n\",\n",
    "    \"4. Line4: Calculates the pseudo r2 score used to evaluate the model performance on the test data by measuring how much variability in the test target data is explained by the model\"\n",
    "   ],\n",
    "   \"id\": \"80b89b249790996e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Logging Neural Network Results into the Model Comparison Report\",\n",
    "   \"id\": \"c81f7d6571abd4c8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"DataPrep.report.loc[len(DataPrep.report)] = [\\\"NN_LE \\\", r2, pseudor2,\\\"\\\", CV_nnmodel.cv_results_['mean_test_score'][CV_nnmodel.best_index_], CV_nnmodel.cv_results_['std_test_score'][CV_nnmodel.best_index_]]\",\n",
    "   \"id\": \"8b4cf16056238160\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line adds a new row to the shared 'DataPrep.report' table documenting the performance metrics of the neural network model trained with label-encoded data.\",\n",
    "   \"id\": \"c9f229704b383866\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Displaying the best hyperparameters\",\n",
    "   \"id\": \"72a680a2d62ca81d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"print(CV_nnmodel.best_params_)\",\n",
    "   \"id\": \"97f05494fbc64807\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line prints the optimal hyperparameter configuration found by 'GridSearchCV' during training of the MLPRegressor\",\n",
    "   \"id\": \"64cda8f9c77e2f5e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Splitting One-Hot Encoded Data for Neural Network Training and Testing\",\n",
    "   \"id\": \"c6b8a7dfa53e9c80\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"(X_train_nn, X_test_nn, Y_train_nn, Y_test_nn) = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)\",\n",
    "   \"id\": \"8598d422ae567bcc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line splits the dataset - specifically the one-hot encoded version - into a training set and a test set preparing it for use with a neural network regression model\",\n",
    "   \"id\": \"511f6ad493efcda3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Grid Search to Train and Tune a Neural Network with One-Hot Encoded Data\",\n",
    "   \"id\": \"80956590c17d9861\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"CV_nnmodel = GridSearchCV(estimator=NNetRregCV, param_grid=param_grid, cv=10,n_jobs=-1)\\n\",\n",
    "    \"CV_nnmodel.fit(X_train_nn, Y_train_nn)\"\n",
    "   ],\n",
    "   \"id\": \"3dbc889752ac0a25\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This code performs automated hyperparameter tuning using 'GridSearchCV' for a neural network regression model trained on one-hot encoded features.\\n\",\n",
    "    \"1. Line1: Wraps the 'MLPRegressor' in a 'GridSearchCV' object to perform an exhaustive search over a grid of hyperparameters\\n\",\n",
    "    \"2. Line2: Trains the model using the training data\"\n",
    "   ],\n",
    "   \"id\": \"3acce970a616e7b8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Calculating r2 score for Neural Network\",\n",
    "   \"id\": \"57fd82fe1a0c50ff\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_train_pred = CV_nnmodel.predict(X_train_nn)\\n\",\n",
    "    \"Y_train_dev = sum((Y_train_nn - Y_train_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_train_nn - Y_train_nn.mean())**2)  # [aus PDF]\\n\",\n",
    "    \"r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]\"\n",
    "   ],\n",
    "   \"id\": \"3fd612181e6e9775\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block manually computes the r2 score for the neural network model trained on one-hot encoded features using the training dataset\\n\",\n",
    "    \"1. Line1: Predicts the target values on the training data using the best neural network selected by 'GridSearchCV'\\n\",\n",
    "    \"2. Line2: Calculates the residual sum of squares (RSS) which represents the total prediction error of the model on the training set.\\n\",\n",
    "    \"3. Line3: Calculates the total sum of squares (TSS) which represents the total variance in the training data assuming a baseline model that always predicts the mean\\n\",\n",
    "    \"4. Line4: Computes the r2 score which measures how well the model explains the variance in the target variable\"\n",
    "   ],\n",
    "   \"id\": \"5d117c4552ead93e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Calculating pseudo r2 score for Neural Network\",\n",
    "   \"id\": \"69e55a4b832b76bd\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_test_pred = CV_nnmodel.predict(X_test_nn)\\n\",\n",
    "    \"Y_test_dev = sum((Y_test_nn - Y_test_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_test_nn - Y_test_nn.mean())**2)  # [aus PDF]\\n\",\n",
    "    \"pseudor2 = 1 - Y_test_dev / Y_train_meandev\"\n",
    "   ],\n",
    "   \"id\": \"af847fb3088b532d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This code block calculates the r2 score on the test dataset (pseudo r2) to evaluate the generalization performance of the neural network trained on one-hot encoded features.\\n\",\n",
    "    \"1. Line1: Uses the trained neural network to predict values for the test set.\\n\",\n",
    "    \"2. Line2: Computes the residual sum of squares (RSS) on the test set and measures the total prediction error made by the model on unseen data\\n\",\n",
    "    \"3. Line3: Calculates the total sum of squares (TSS) on the test data\\n\",\n",
    "    \"4. Line4: Calculates the test r2 (pseudo r2) which reflects how well the model generalizes to new data\"\n",
    "   ],\n",
    "   \"id\": \"316893efb4ea9d35\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Logging Neural Network Results to the Report\",\n",
    "   \"id\": \"27a702d732430c9a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"DataPrep.report.loc[len(DataPrep.report)] = [\\\"NN_OH \\\", r2, pseudor2,\\\"\\\", CV_nnmodel.cv_results_['mean_test_score'][CV_nnmodel.best_index_], CV_nnmodel.cv_results_['std_test_score'][CV_nnmodel.best_index_]]\\n\",\n",
    "    \"print(DataPrep.report.head())\\n\",\n",
    "    \"print(CV_nnmodel.best_params_)\"\n",
    "   ],\n",
    "   \"id\": \"b402a7e2b5bed92d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This block adds a new row to your 'DataPrep.report' table to document the performance of a neural network model trained on one-hot encoded features and then displays the first few rows of the report and the best hyperparameters found during grid search.\",\n",
    "   \"id\": \"d3f90190be154f4f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"## OLS Regression\",\n",
    "   \"id\": \"8b88c6098b6e4ade\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Importing Libraries and Project Modules for Linear Regression\",\n",
    "   \"id\": \"476196c847f7f693\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from sklearn.linear_model import LinearRegression\\n\",\n",
    "    \"from sklearn.metrics import mean_squared_error, r2_score\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"import DataPrep\"\n",
    "   ],\n",
    "   \"id\": \"c0a051e1f7bde74e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This block imports all the necessary libraries and modules to perform linear regression modeling, evaluation and visualization - using built-in tools from 'scikit-learn' and 'DataPrep'\",\n",
    "   \"id\": \"9100372067b7b649\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Splitting label-encoded data for OLS regression\",\n",
    "   \"id\": \"d22c621249dd17b1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"X_train_OLS, X_test_OLS, Y_train_OLS, Y_test_OLS = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)\",\n",
    "   \"id\": \"435d381e8025002d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line splits the label-encoded dataset into training and testing sets to prepare for training a Ordinary Least Square (OLS) regression model.\",\n",
    "   \"id\": \"8a117ff84daed930\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Set model specs\",\n",
    "   \"id\": \"b441d091749fce51\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"ols_model = LinearRegression()\\n\",\n",
    "    \"ols_model.fit(X_train_OLS, Y_train_OLS)\"\n",
    "   ],\n",
    "   \"id\": \"a49e81de5fae0bb3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates and fits an Ordinary Least Square linear regression model for the training data.\\n\",\n",
    "    \"1. Line1: Initializes a new instance of 'LinearRegression' from 'scikit-learn' which assumes a linear relationship between the input features and the target variable.\\n\",\n",
    "    \"2. Line2: Fits the model on the training dataset and learns the optimal coefficients (ß) and intercept to minimize the sum of squared errors between predicted and actual values.\"\n",
    "   ],\n",
    "   \"id\": \"8643c1810ba9d289\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Prediction and Result\",\n",
    "   \"id\": \"81d2794e867b18b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"y_train_pred = ols_model.predict(X_train_OLS)\\n\",\n",
    "    \"y_test_pred = ols_model.predict(X_test_OLS)\\n\",\n",
    "    \"\\n\",\n",
    "    \"r2_train = r2_score(Y_train_OLS, y_train_pred)\\n\",\n",
    "    \"r2_test = r2_score(Y_test_OLS, y_test_pred)\\n\",\n",
    "    \"\\n\",\n",
    "    \"DataPrep.report.loc[len(DataPrep.report)] = ['OLS RegressionLC', r2_train, r2_test,np.sqrt(mean_squared_error(Y_test_OLS, y_test_pred)), \\\"\\\", \\\"\\\"]\"\n",
    "   ],\n",
    "   \"id\": \"fe32c0d718211a45\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block generates predictions using the OLS model, calculates performance metrics and stores the results in the model comparison report ('DataPrep.report').\\n\",\n",
    "    \"1. Line1: Predicts the target variable for the training dataset using the fitted OLS model.\\n\",\n",
    "    \"2. Line2: Predicts the target variable for the test dataset using the fitted OLS model.\\n\",\n",
    "    \"3. Line4: Calculates the coefficient of determination (r2) for the training set.\\n\",\n",
    "    \"4. Line5: Calculates the coefficient of determination (r2) for the test set.\\n\",\n",
    "    \"5. Line7: Calculates Root Mean Squared Error (RMSE) for the test set and appends a row to the 'DataPrep.report' with the model name, r2 scores, RMSE scores.\"\n",
    "   ],\n",
    "   \"id\": \"31f788617dc91218\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Residual plot based on OLS result\",\n",
    "   \"id\": \"866c2a030623d604\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"residuals = Y_test_OLS - y_test_pred\\n\",\n",
    "    \"plt.scatter(Y_test_OLS, residuals)\\n\",\n",
    "    \"plt.axhline(0, color='r', linestyle='--')\\n\",\n",
    "    \"plt.xlabel(\\\"Selling price\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Residual\\\")\\n\",\n",
    "    \"plt.title(\\\"Residual plot - OLS LE\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"6e9ebabb2844d605\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block generates a residual plot which is a key diagnostic tool for evaluating the quality of a regression model.\\n\",\n",
    "    \"1. Line1: Calculates the residuals.\\n\",\n",
    "    \"2. Line2: Creates a scatter plot of redsiduals against the actual selling prices which helps to detect patterns that indicate model bias or non-linearity.\\n\",\n",
    "    \"3. Line3: Draws a horizontal red dashed line at residual = 0 -> representing perfect predictions; Points above the line -> underprediction; Points below the line -> overprediction\\n\",\n",
    "    \"4. Line4 - Line6: Adds axis names and proper layout\\n\",\n",
    "    \"5. Line7: Prevents overlapping elements\\n\",\n",
    "    \"6. Line8: Displays the plot\"\n",
    "   ],\n",
    "   \"id\": \"43b4d3a175b9c0a6\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Splitting One-Hot Label Encoded Data\",\n",
    "   \"id\": \"aadecc53d4d53245\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"X_train_OLS, X_test_OLS, Y_train_OLS, Y_test_OLS = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)\",\n",
    "   \"id\": \"47d12e2b0256f85a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line splits the one-hot encoded dataset into training and testing sets to prepare for training and evaluating an OLS regression model.\",\n",
    "   \"id\": \"15723d255a161411\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Training an OLS regression model\",\n",
    "   \"id\": \"9c6e1cbc7b9dc09\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"ols_model = LinearRegression()\\n\",\n",
    "    \"ols_model.fit(X_train_OLS, Y_train_OLS)\"\n",
    "   ],\n",
    "   \"id\": \"1ee611be889f77d0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates and trains an OLS linear regression model using one-hot encoded features as input\\n\",\n",
    "    \"1. Line1: Initiates a new linear regression model from 'scikit-learn'\\n\",\n",
    "    \"2. Line2: Trains the model on the training dataset\"\n",
    "   ],\n",
    "   \"id\": \"f3a0ab3759bf5080\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Evaluate and log performance of OLS regression\",\n",
    "   \"id\": \"2d2f94f826565933\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"y_train_pred = ols_model.predict(X_train_OLS)\\n\",\n",
    "    \"y_test_pred = ols_model.predict(X_test_OLS)\\n\",\n",
    "    \"\\n\",\n",
    "    \"r2_train = r2_score(Y_train_OLS, y_train_pred)\\n\",\n",
    "    \"r2_test = r2_score(Y_test_OLS, y_test_pred)\\n\",\n",
    "    \"\\n\",\n",
    "    \"DataPrep.report.loc[len(DataPrep.report)] = ['OLS RegressionOH', r2_train, r2_test,np.sqrt(mean_squared_error(Y_test_OLS, y_test_pred)), \\\"\\\", \\\"\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(DataPrep.report.head())\"\n",
    "   ],\n",
    "   \"id\": \"f701e608869c720\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block generates predictions using the trained OLS model, computes performance metrics and appends the results to the centralized model comparison report.\\n\",\n",
    "    \"1. Line1: Predicts selling prices for training data using the OLS model.\\n\",\n",
    "    \"2. Line2: Predicts selling prices for test data using the OLS model.\\n\",\n",
    "    \"3. Line4: Calculates the coefficient of determination (r2) for the training set.\\n\",\n",
    "    \"4. Line5: Calculates the coefficient of determination (r2) for the test set.\\n\",\n",
    "    \"5. Line7: Calculates Root Mean Squared Error (RMSE) for the test set and appends a row to the 'DataPrep.report' with the model name, r2 scores, RMSE scores.\\n\",\n",
    "    \"6. Line9: Displays the first few rows of the report to confirm logging was successful.\"\n",
    "   ],\n",
    "   \"id\": \"1daacc13ca09ae85\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Residual plot for OLS regression\",\n",
    "   \"id\": \"26983cfe8de8409e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"residuals = Y_test_OLS - y_test_pred\\n\",\n",
    "    \"plt.scatter(Y_test_OLS, residuals)\\n\",\n",
    "    \"plt.axhline(0, color='r', linestyle='--')\\n\",\n",
    "    \"plt.xlabel(\\\"Selling price\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Residual\\\")\\n\",\n",
    "    \"plt.title(\\\"Residual plot - OLS OH\\\")\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"6166b12092d2864f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block creates a residual plot to visualize the prediction errors of the OLS regression model trained on one-hot encoded data.\\n\",\n",
    "    \"1. Line1: Calculates the residuals\\n\",\n",
    "    \"2. Line2: Creates a scatter plot of redsiduals against the actual selling prices which helps to detect patterns that indicate model bias or non-linearity.\\n\",\n",
    "    \"3. Line3: Draws a horizontal red dashed line at residual = 0 -> representing perfect predictions; Points above the line -> underprediction; Points below the line -> overprediction\\n\",\n",
    "    \"4. Line4 - Line6: Adds axis names and proper layout\\n\",\n",
    "    \"5. Line7: Prevents overlapping elements\\n\",\n",
    "    \"6. Line8: Displays the plot\"\n",
    "   ],\n",
    "   \"id\": \"b20014338692afd0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"## Random Forest\",\n",
    "   \"id\": \"b37d193bcdf756a2\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Importing Libraries for Random Forest Regression\",\n",
    "   \"id\": \"6d503eb58016ef4f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from sklearn.ensemble import RandomForestRegressor\\n\",\n",
    "    \"from sklearn.model_selection import GridSearchCV, train_test_split\\n\",\n",
    "    \"from JupiterPycharmProjekt import DataPrep\"\n",
    "   ],\n",
    "   \"id\": \"85bbb901d609e49a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This code imports the necessary libraries and modules to build and optimize a RandomForest regression model using the prepared dataset.\\n\",\n",
    "    \"1. Line1: Imports the 'RandomForestRegressor' which combines many decision trees and averages their predictions to improve accuracy and reduce overfitting.\\n\",\n",
    "    \"2. Line2: Imports 'GridSearchCV' for hyperparameter tuning using cross-validation and 'train_test_split' to split the dataset into training and testing sets.\\n\",\n",
    "    \"3. Line3: Imports 'DataPrep'\"\n",
    "   ],\n",
    "   \"id\": \"ed5089f77bc3062\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Defining a hyperparameter grid for random forest regression\",\n",
    "   \"id\": \"a0b893978b7e2e4\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"param_grid = {\\n\",\n",
    "    \"    'max_depth': [4, 5, 6, 7, 8],\\n\",\n",
    "    \"    'n_estimators': [10, 50, 100, 150, 200],\\n\",\n",
    "    \"    'criterion': ['squared_error', 'absolute_error']  # [Fix] gültige Kriterien für RandomForestRegressor\\n\",\n",
    "    \"}\"\n",
    "   ],\n",
    "   \"id\": \"a1e8ea8930060a9c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This defines a grid of hyperparameters for tuning a 'RandomForestRegressor' using grid search with cross-validation.\\n\",\n",
    "    \"1. Line1: Defines the maximum depth of each decision tree in the forest\\n\",\n",
    "    \"2. Line2: Indicates the number of tree's in the random forest\\n\",\n",
    "    \"3. Line3: Indicates the function used to measure the quality of a split in each tree\"\n",
    "   ],\n",
    "   \"id\": \"ee092fc5c8ff8706\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Train-Test split for Random Forest\",\n",
    "   \"id\": \"8d2648f7947a48a7\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"(X_train_RF, X_test_RF, Y_train_RF, Y_test_RF) = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)\",\n",
    "   \"id\": \"9e14bac453dccbd\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line splits the label-encoded dataset into training and testing subsets for training a Random Forest regression model.\",\n",
    "   \"id\": \"6fcafe027c2e0d83\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Initialize Random Forest Regressor\",\n",
    "   \"id\": \"d207752869aa7a83\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": \"RForregCV = RandomForestRegressor(random_state=42)\",\n",
    "   \"id\": \"85afbe9605881465\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"This line creates a Random Forest Regressor instance with a fixed random seed for reproducibility.\",\n",
    "   \"id\": \"4ad5a5db38ce5eae\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Hyperparameter Tuning for Random Forest using Grid search\",\n",
    "   \"id\": \"90ee0f0e4718c28f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"CV_rfmodel = GridSearchCV(estimator=RForregCV, param_grid=param_grid, cv=4, n_jobs=-1)\\n\",\n",
    "    \"CV_rfmodel.fit(X_train_RF, Y_train_RF)\"\n",
    "   ],\n",
    "   \"id\": \"429530d613dc36c3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block performs automated hyperparameter optimization of a Random Forest model using 4-fold cross-validation on the training data.\\n\",\n",
    "    \"1. Line1: Creates a GridSearch object to systemically test multiple combinations of hyperparameters for the Random Forest model\\n\",\n",
    "    \"2. Line2: Executes the grid search\"\n",
    "   ],\n",
    "   \"id\": \"b0bdc5c7a3b1c3ec\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### r2 score calculation for Random Forest on training set\",\n",
    "   \"id\": \"dc60c99e6b38c130\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_train_pred = CV_rfmodel.predict(X_train_RF)\\n\",\n",
    "    \"Y_train_dev = sum((Y_train_RF - Y_train_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_train_RF - Y_train_RF.mean())**2)\\n\",\n",
    "    \"r2 = 1 - Y_train_dev / Y_train_meandev\"\n",
    "   ],\n",
    "   \"id\": \"6710ee1fb1f5969f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block manually computes the coefficient of determination for the Random Forest models performance on the training data.\\n\",\n",
    "    \"1. Line1: Predicts target values using the best fitted Random Forest model on the training set\\n\",\n",
    "    \"2. Line2: Calculates the sum of squares residuals (SSR) to predict how far values deviate from the actual values.\\n\",\n",
    "    \"3. Line3: Calculates the total sum of squares (TSS) to measure the total variance in the actual target values.\\n\",\n",
    "    \"4. Line4: Computes the r2 score which indicates how much of the variance in 'Y_train_RF' is explained by the model.\"\n",
    "   ],\n",
    "   \"id\": \"b0550bad20008d99\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Evaluate Random Forest Performance on the test set\",\n",
    "   \"id\": \"778138f8837281e0\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"Y_test_pred = CV_rfmodel.predict(X_test_RF)\\n\",\n",
    "    \"Y_test_dev = sum((Y_test_RF - Y_test_pred)**2)\\n\",\n",
    "    \"Y_test_meandev = sum((Y_test_RF - Y_test_RF.mean())**2)\\n\",\n",
    "    \"pseudor2 = 1 - Y_test_dev / Y_test_meandev\"\n",
    "   ],\n",
    "   \"id\": \"d564494b502f196f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block computes the pseudo-r2 score for the Random Forest model on the unseen test data.\\n\",\n",
    "    \"1. Line1: Uses the best model from 'GridSearchCV' to predict the target values for the test set.\\n\",\n",
    "    \"2. Line2: Calculates the sum of squared errors (residuals) between actual and predicted values on the test set.\\n\",\n",
    "    \"3. Line3: Computes the total sum of squares (variance) in the actual test targets.\\n\",\n",
    "    \"4. Line4: Calculates the coefficient of determination on the test set (pseudo-r2) which indicates how well the model explains variance in unseen data.\"\n",
    "   ],\n",
    "   \"id\": \"ab08b639c614735e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Logging Random Forest Results and Displaying Best Parameters\",\n",
    "   \"id\": \"5d540ee4aa529b6\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"DataPrep.report.loc[len(DataPrep.report)] = [\\\"RF_LC \\\", r2, pseudor2,\\\"\\\", CV_rfmodel.cv_results_['mean_test_score'][CV_rfmodel.best_index_], CV_rfmodel.cv_results_['std_test_score'][CV_rfmodel.best_index_]]\\n\",\n",
    "    \"print(CV_rfmodel.best_params_)\"\n",
    "   ],\n",
    "   \"id\": \"468a553fc9304dbc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block logs the performance of the Random Forest model into a central comparison report and prints the best hyperparameters found during grid search.\\n\",\n",
    "    \"1. Line1: Appends a new row to the report DataFrame for model comparison\\n\",\n",
    "    \"2. Line2: Outputs the best combination of hyperparameters found by 'GridSearchCV'\"\n",
    "   ],\n",
    "   \"id\": \"dc59b6d0510a8fdb\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### Random Forest Training and Evaluation (One-Hot Encoded Features)\",\n",
    "   \"id\": \"85dc628866673203\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"(X_train_RF, X_test_RF, Y_train_RF, Y_test_RF) = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"RForregCV = RandomForestRegressor(random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"CV_rfmodel = GridSearchCV(estimator=RForregCV, param_grid=param_grid, cv=4, n_jobs=-1)\\n\",\n",
    "    \"CV_rfmodel.fit(X_train_RF, Y_train_RF)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Y_train_pred = CV_rfmodel.predict(X_train_RF)\\n\",\n",
    "    \"Y_train_dev = sum((Y_train_RF - Y_train_pred)**2)\\n\",\n",
    "    \"Y_train_meandev = sum((Y_train_RF - Y_train_RF.mean())**2)\\n\",\n",
    "    \"r2 = 1 - Y_train_dev / Y_train_meandev\"\n",
    "   ],\n",
    "   \"id\": \"7c12813474aa89d1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"This block trains a Random Forest Regressor on one-hot encoded input features, tunes its hyperparameters with grid search and 4-fold cross-validation and then evaluates the model on the training data using the r2-score.\\n\",\n",
    "    \"1. Line1: Train-test split with one-hot encoded features\\n\",\n",
    "    \"2. Line3: Random Forest Model initialization with fixed randomness.\\n\",\n",
    "    \"3. Line5 - Line6: Hyperparameter tuning using grid-search\\n\",\n",
    "    \"4. Line8 - Line11: Training set evaluation with r2 score calculation\"\n",
    "   ],\n",
    "   \"id\": \"4469c5dd6911cd4b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"####\",\n",
    "   \"id\": \"bd84b19404e4640e\"\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "94ac67437fb4b85a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
