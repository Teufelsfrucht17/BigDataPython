{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Big Data Project\n",
    "## Data Preparation\n",
    "\n",
    "### General\n",
    "In this section the environment for Data Preparation is set up by importing essential Python libraries. Each library plays a key role for the Data Preparation."
   ],
   "id": "43a749f873f2d9c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ],
   "id": "ad010c5cd048786"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pandas:             Used for handling and analyzing structured data\n",
    "\n",
    "matplotlib.pyplot:  A fundamental plotting library.\n",
    "\n",
    "seaborn:            Built on top of matplotlib and simplifies the process of graphical statistics.\n",
    "\n",
    "sklearn.model_selection + train_test_split: Helps to split a dataset into training and test dataset.\n",
    "\n",
    "sklearn.preprocessing + LabelEncoder: Transforming data before feeding it into a model.\n",
    "\n",
    "numpy: Is the foundational package for numerical computing in Python."
   ],
   "id": "e13ea412b5d512fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read original data from CSV",
   "id": "ce4cd1c0ed384672"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data = pd.read_csv('UsedCarSellingPrices.csv')",
   "id": "2047ddd961ca759"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This code uses pandas to read the CSV file \"Used Car Selling Prices\" and loads it into a dataframe called 'data'.",
   "id": "1d92823130b25d88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Label-Encoding for Visualisation before cleaning",
   "id": "adaa2653be36124d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Define columns that need to be lable-encoded",
   "id": "636111fe5ed46561"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']",
   "id": "a126c643f97ea4e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This line defines a list of column names that represent categorical features in the dataset.\n",
    "\n",
    "fuel: type of fuel that is used by the car\n",
    "\n",
    "seller_type: type of car seller\n",
    "\n",
    "transmission: type of gear\n",
    "\n",
    "owner: status of ownership"
   ],
   "id": "5ac874040e0796fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Copy data into var label_encoded_data; create empty array lable_encoders",
   "id": "211c5b124578ebcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "label_encoded_data = data.copy()\n",
    "label_encoders = {}"
   ],
   "id": "23182f4175e5701a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This code sets up the environment for label encoding.\n",
    "\n",
    "Line1: Copying the dataset\n",
    "\n",
    "Line2: Initializing the Encoders Dictionary"
   ],
   "id": "86d7636dd8db33ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Run lable-encoder for every previosly defined columne (function imported from sklearn)",
   "id": "4a2da6e4f580939"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded_data[col] = le.fit_transform(label_encoded_data[col])\n",
    "    label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "print(\"\\nLabel-Encoded Data for Visualisation:\")\n",
    "print(label_encoded_data.head())"
   ],
   "id": "c722850efc7b5807"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This loop iterates over each categorical column and applies Label Encoding transforming string labels into numeric codes.\n",
    "\n",
    "1. for col in categorical_columns: Loops through each column listed earlier\n",
    "2. le = labelEncoder(): Creates a new LabelEncoder instance from scikit-learn for the current column\n",
    "3. label_encoded_data[col] = le.fit_transform(label_encoded_data[col]): Fits the encoder to the column's categories and transforms them into integers + Replaces the original text values in label_encoded_data with the corresponding numeric labels\n",
    "4. label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_))): Stores the mapping of original category names to their encoded values in the label_encoders dictionary + This allows to trace or reverse the encoding later if needed"
   ],
   "id": "7dffe45da4a60e92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### concatinates x and y into one point to be visualized",
   "id": "97539411ff127a8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "all_data_LableEncoded = pd.concat([label_encoded_data], axis=1)",
   "id": "2ca869967239fb39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line creates a new DataFrame called 'all_data_LableEncoded' by concatenating 'label_encoded_data' along the column axis 'axis=1'",
   "id": "537562c7d71a7d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Drops all columes that are non-numeric to make scaling possible",
   "id": "b54fe462afa4a1ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "all_data_LableEncoded = all_data_LableEncoded.select_dtypes(include=['number'])",
   "id": "c30cefb4a2a48ded"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line filters the dataset to keep only the numeric columns from 'all_data_LableEncoded'.",
   "id": "568b8059b8e5d82a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Scale data (normalized via MinMaxScaler - between 0 and 1)\n",
    "sscaler = preprocessing.StandardScaler()    ???\n",
    "\n",
    "all_data_LableEncoded = sscaler.fit_transform(all_data_LableEncoded)    ???"
   ],
   "id": "800483278abd6868"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nscaler = preprocessing.MinMaxScaler()\n",
    "all_data_LableEncoded = nscaler.fit_transform(all_data_LableEncoded)"
   ],
   "id": "bb45956ed8cc7525"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block performs Min-Max Scaling on the numeric features in the dataset, transforming them into a commonscale between 0 and 1.\n",
    "1. Line1: Initalizes a MinMaxScaler object from scikit-learn\n",
    "2. Line2: Calculates the min and max values for each feature iin the dataset and applies the scaling transformation to each value"
   ],
   "id": "51ed3765be9ad937"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualisation before cleaning Data",
   "id": "318d63feac080e29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Reintegrates Column name for boxplot",
   "id": "914c7df65d5ebf6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scaled_df = pd.DataFrame(all_data_LableEncoded, columns=label_encoded_data.select_dtypes(include='number').columns)",
   "id": "c0f59e3af51b2e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line converts the scaled NumPy array (from the Min-Max Scaler) back into a pandas DataFrame and restores the original column names.",
   "id": "6a3e41802100a48b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Boxplot with readable x-axis",
   "id": "ab1fa02b4c7ea8f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=scaled_df, orient='v', palette='Set2')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Normed boxplot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "21635a8334e1f982"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block creates a boxplot for each feature in the 'scaled_df' DataFrame to visualize the distribution and spread of the normalized (Min-max scaled) data.\n",
    "1. Line1: Sets the size of the figure to be 12 inches wide by 6 inches tall and ensures the plot is large enough to accommodate all features without crowding.\n",
    "2. Line2: Creates a vertical boxplot for each column in the 'scaled_df' DataFrame and uses Seaborn's elegant and color-friendly 'Set2' palette. Each box shows the median, the IQR and Whiskers & Outliers.\n",
    "3. Line3: Rotates the x-axis labels by 45 degrees for better readability, especially when there are many features.\n",
    "4. Line4: Adds a title to the plot for context, signaling that the data is normalized.\n",
    "5. Line5: Adjusts spacing to prevent overlap between axis labels, titles, and plot content.\n",
    "6. Line6: Renders and displays the final plot in the notebook."
   ],
   "id": "95cc2a4e33e73f7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Boxplot for only numerical data",
   "id": "553d97e51b56ff55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "selected_cols = ['selling_price', 'km_driven', 'year']\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=scaled_df[selected_cols], orient='v', palette='Set3')\n",
    "plt.title(\"Normed boxplot for numerical data only\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c031fe8c9c522fee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This blocks generates a boxplot visualization focused on three specific, scaled numerical features:\n",
    "\n",
    "'selling_price'\n",
    "\n",
    "'km_driven'\n",
    "\n",
    "'year'\n",
    "\n",
    "1. Line1: Selects the subset of important numerical features for focused analysis.\n",
    "2. Line2: Sets the plot size to be 8 inches wide and 5 inches tall.\n",
    "3. Line3: Creates a vertical boxplot for just the selected columns using the soft, pastel 'Set3' color palette from Seaborn.\n",
    "4. Line4: Adds a descriptive title to clarify that this plot shows normalized (scaled) numerical features.\n",
    "5. Line5: Ensures layout is adjusted for neatness and then displays the plot."
   ],
   "id": "8ab645fd572c712c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Pairplot to show correlation",
   "id": "2c73fec383780273"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.pairplot(scaled_df[selected_cols])\n",
    "plt.suptitle(\"Pairplot for select charactaristics\", y=1.02)\n",
    "plt.show()"
   ],
   "id": "7d6f172ff0f468e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This blocks creates a pairplot to visually explore pairwise relationships among the selected numerical features:\n",
    "\n",
    "'selling_price'\n",
    "\n",
    "'km_driven'\n",
    "\n",
    "'year'\n",
    "\n",
    "1. Line1: Creates a grid of scatterplots for each pairwise combination of the selected features. This helps to visualize Correlations, Clustering tendencies and Linearity or Non-Linearity Relationships. The Histograms are shown on the diagonal to represent each variable's distribution.\n",
    "2. Line2: Adds a super title above the entire plot grid.\n",
    "3. Line3: Renders the entire pairplot for viewing."
   ],
   "id": "20015cca9252c598"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clean Data & Create variable Brand",
   "id": "40d32e9f2195e0f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Remove missing data",
   "id": "aa6db92fe290c3a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data = data.dropna()",
   "id": "ca55134311fde7de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line removes all rows with missing values from the 'data' DataFrame.",
   "id": "137f5d67f47f07ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Show how much data was removed",
   "id": "453412919edc164b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Data after removing data:\")\n",
    "print(data.isnull().sum())\n",
    "print(f\"Remaining rows: {len(data)}\")"
   ],
   "id": "8bedb4c7d57d35f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block checks and confirms that all missing values have been removed from the dataset and reports the number of remaining rows.\n",
    "\n",
    "1. Line1: Prints a header to indicate that the following output relates to the cleaned dataset.\n",
    "2. Line2: Checks for missing values in each column of the 'data' DataFrame, creates a Boolean mask of the same shape as the data and then counts the number of 'True' values in each column, i.e. the number of missing entries.\n",
    "3. Line3: Prints the total number of rows left in the dataset after dropping rows with missing values using 'len(data)'."
   ],
   "id": "2ec06b73fc2937c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### IQR-based Removal of Outliers",
   "id": "15d94a870e94853d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = np.percentile(df[column], 25)\n",
    "    Q3 = np.percentile(df[column], 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]"
   ],
   "id": "4c2f625bd763d22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This function removes outliers from a specific column in a DataFrame using the Interquartile Range (IQR) method\n",
    "\n",
    "1. 'Q1': 25th percentile - the value below which 25% of the data falls\n",
    "2. 'Q3': 75th percentile - the value below which 75% of the data falls\n",
    "3. 'IQR = Q3-Q1': IQR is the spread of the middle 50% of values and it is used to understand the natural range of variation in the data.\n",
    "4. Line5 + Line6: These define the acceptable range and any values below the lower bound or above the upper bound are considered outliers.\n",
    "5. Line7: Returns a filtered version of the original DataFrame, keeping only the rows where the specified column's value is within the acceptable range -> Outlier are removed."
   ],
   "id": "18841f9550170801"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Apply to most important column",
   "id": "a20f64473b0e5d0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = remove_outliers_iqr(data, 'selling_price')\n",
    "data = remove_outliers_iqr(data, 'km_driven')"
   ],
   "id": "3aca6d49a4bdbcc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These lines apply the IQR-based outlier removal function to two important columns in the dataset: 'selling_price' and 'km_driven'.\n",
    "\n",
    "1. Line1: Removes rows where 'selling_price' is considered an outlier based on the IQR rule and keeps only cars with selling prices within the typical range.\n",
    "2. Line2: Applies the same IQR filtering to the 'km_driven' column and eliminates unusually low or high mileage entries that could distort statistical analysis or model training."
   ],
   "id": "7b4af52698a24f65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\nDaten nach IQR-basierter Ausreißerbereinigung:\")\n",
    "print(f\"Max. Verkaufspreis: {data['selling_price'].max()}\")\n",
    "print(f\"Max. Kilometerstand: {data['km_driven'].max()}\")\n",
    "print(f\"Verbleibende Zeilen nach IQR-Filter: {len(data)}\")"
   ],
   "id": "52ec2cf89495988b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block prints a quick summary of the dataset after removing outliers using the IQR method.\n",
    "1. Line1: Prints a headline used for clarity when reading the console output.\n",
    "2. Line2: Displays the maximum selling price in the cleaned dataset which helps verifying that extremely high prices have been removed.\n",
    "3. Line3: Shows the maximum odometer reading after outlier removal and ensures that unusally high mileage values have been filtered out.\n",
    "4. Line4: Prints the number of remaining rows in the dataset which tells how much data is left after removing rows that contained outliers in 'selling_price' and 'km_driven'."
   ],
   "id": "542b32c7b2a47b40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create 'Brand' as new column",
   "id": "4fd7b57da12e5d2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data['brand'] = data['name'].str.split().str[0]\n",
    "print(data)"
   ],
   "id": "24c854c0446ecc73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line creates a new column called 'brand' by extracting the first word from the 'name' column which represents the car brand.",
   "id": "bd2c2e327c96cbb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Label-Encoding for Visualisation after cleaning",
   "id": "5b622991c547475f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ???",
   "id": "b0de47c75bf931c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']\n",
    "label_encoded_data = data.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded_data[col] = le.fit_transform(label_encoded_data[col])\n",
    "    label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "print(\"\\nLabel-Encoded Data (nur zur Referenz):\")\n",
    "print(label_encoded_data.head())"
   ],
   "id": "b992b00d1f2b76cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block performs label encoding on selected categorical columns, converting them from text values to integers so they can be used in regression models.\n",
    "\n",
    "1. Line1: Specifies the list of categorical features to be encoded which are typically textual descriptors that must be converted into numeric format for modeling.\n",
    "2. Line2: Creates a copy of the original dataset to apply the encodings without altering the raw data.\n",
    "3. Line3: Initializes an empty dictionary to store the encoding mappings for each categorical column.\n",
    "4. The 'for' loop: Iterates over each column in the 'categorical_columns' list; The 'LabelEncoder()' from scikit-learn is used to convert category labels into integers. The transformed values replace the original column in 'label_encoded_data'. The mapping of original class labels to integer codes is stored in 'label_encoders' for reference or inverse transformation later.\n",
    "5. Line10 + Line11: Displays the first few rows of the updated dataset to confirm that the categorical features have been encoded."
   ],
   "id": "ae11aef1a4a852dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### concatinate x and y into one point to be visualized",
   "id": "3d56e804c3a3f7e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "all_data_LableEncoded = pd.concat([label_encoded_data], axis=1)",
   "id": "ac631a3c3f70be56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line creates a new DataFrame called 'all_data_LableEncoded' by concatenating the contents of 'label_encoded_data' along the columns axis.",
   "id": "a02b2277ecc55596"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Drop all columns that are non-numeric to make scaling possible",
   "id": "b799a1b7a761fd44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "all_data_LableEncoded = all_data_LableEncoded.select_dtypes(include=['number'])",
   "id": "e876c32cc5528ba7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line filters the 'all_data_LableEncoded' DataFrame to include only numeric columns, removing any that are not numeric.",
   "id": "3b2f2c9998065419"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Scale data (normalized)\n",
    "\n",
    "sscaler = preprocessing.StandardScaler()\n",
    "\n",
    "all_data_LableEncoded = sscaler.fit_transform(all_data_LableEncoded)"
   ],
   "id": "87e0e4d63d317422"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nscaler = preprocessing.MinMaxScaler()\n",
    "all_data_LableEncoded = nscaler.fit_transform(all_data_LableEncoded)"
   ],
   "id": "2778291857293e1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This code applies Min-Max Scaling to normalize all numeric features in the dataset, transforming their values to a common range between 0 and 1.\n",
    "1. Line1: Initializes a MinMaxScaler object from scikit-learn's 'preprocessing' module and will scale each feature individually.\n",
    "2. Line2: Calculates the minimum and maximum values for each feature and scales each value in the dataset to the 0-1 range."
   ],
   "id": "db75c81582c47c0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualization after Data cleaning",
   "id": "a5b963da4ad7e3fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Scale Data ???",
   "id": "9b6560abdce3e4e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "scaled_df = pd.DataFrame(all_data_LableEncoded, columns=label_encoded_data.select_dtypes(include='number').columns)",
   "id": "b06fcc296cd5e11d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line converts the scaled NumPy array back into a pandas DataFrame and restores the original column names, making the data human-readable and easier to work with.",
   "id": "99f0ed241a400120"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Boxplot with readable axis names",
   "id": "7ce6514781db7cf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=scaled_df, orient='v', palette='Set2')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot der skalierten numerischen Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "77115866ff932066"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block creates a boxplot for all features in the 'scaled_df' DataFrame, which contains only scaled numeric data. The plot helps visually inspecting the distribution and variability of each feature.\n",
    "1. Line1: Sets the figure size to 12 inches wide by 6 inches tall for better readability.\n",
    "2. Line2: Uses Seaborn to draw vertical boxplots for each numeric feature in 'scaled_df' and 'palette=Set2' gives the plot a soft, color-coded appearance to distinguish features visually.\n",
    "3. Line3: Rotates the x-axis labels by 45 degrees so that long feature names dont overlap and remain legible.\n",
    "4. Line4: Adds a descriptive title\n",
    "5. Line5 + Line6: Adjusts the layout to avoid overlapping elements and displays the final plot."
   ],
   "id": "7ec0aa4417ca0591"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Boxplot only for selected numeric columns",
   "id": "9849f41d1ddf0c6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "selected_cols = ['selling_price', 'km_driven', 'year']\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=scaled_df[selected_cols], orient='v', palette='Set3')\n",
    "plt.title(\"Boxplot ausgewählter Merkmale\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f5c70ed402522bd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block creates a boxplot visualization for a selected subset of key numeric features: 'selling_price', 'km_driven' and 'year', all of which have been previously scaled to 0-1 range.\n",
    "1. Line1: Selects the three features for targeted visualization.\n",
    "2. Line2: Sets the figure size to 8 inches wide and 5 inches tall for compact clarity.\n",
    "3. Line3: Draws vertical boxplots for just the selected columns using Seaborn's pastel 'Set3' color palette.\n",
    "4. Line4: Adds a title.\n",
    "5. Line5 + Line6: Adjusts spacing to prevent overlap and displays the plot."
   ],
   "id": "3412ee8bd6ffa66a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Pairplot for Distribution and Correlation",
   "id": "8dde95221dbd9000"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sns.pairplot(scaled_df[selected_cols])\n",
    "plt.suptitle(\"Paarweise Verteilungen ausgewählter Merkmale\", y=1.02)\n",
    "plt.show()\n",
    "#print(\"Trainingsdaten zusätzlich als 'prepared_used_car_data_train.parquet' gespeichert.\")\n",
    "#print(\"Testdaten zusätzlich als 'prepared_used_car_data_test.parquet' gespeichert.\")\n",
    "#print(\"Gesamtdaten zusätzlich als 'prepared_used_car_data.parquet' gespeichert.\")"
   ],
   "id": "d4cddbba60eae9df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block creates a pairplot that visualizes the pairwise relationships and distributions of three selected, scaled features: 'selling_price', 'km_driven' and 'year'.\n",
    "1. Line1: Generates a grid of plots: Scatter plots and Histograms.\n",
    "2. Line2: Adds a descriptive title above the plot grid; 'y=1.02' adjusts the title position slightly above the plot area to prevent overlap.\n",
    "3. Line3: Renders and displays the plot."
   ],
   "id": "ff8b32c1a9301931"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### One-Hot-Encoding for Regression Model Training & Testing",
   "id": "7afb4ecd9e7f6f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### One-Hot-Encoding for categorical Variables",
   "id": "412c72b4510faa63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ncoded_data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(\"\\nOne-Hot-Encoded Data:\")\n",
    "print(encoded_data.head())\n",
    "\n",
    "print(encoded_data)"
   ],
   "id": "a6f7e24bde3e3f2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block uses one-hot encoding to transform categorical columns in the dataset into binary 0 or 1 columns, making them suitable for regression models.\n",
    "1. Line1: Performs one-hot encoding on the columns listed in 'categorical_columns'. For each unique category in these columns, new binary columns are created. Drops the first category for each column to avoid multicollinearity when using models like linear regression.\n",
    "2. Line3: Prints a header for clarity in console output.\n",
    "3. Line4: Displays the first few rows of the encoded dataset for a quick preview.\n",
    "4. Line6: Prints the entire DataFrame, which now contains both numeric and one-hot encoded binary columns."
   ],
   "id": "bf53c95f9b307d35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sort data by 'year' and 'km_driven'",
   "id": "b882593da83debe1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "encoded_data_sorted = encoded_data.sort_values(by=['year', 'km_driven'], ascending=[False, True])",
   "id": "2629b0bf781225dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line sorts the encoded dataset based on two columns - 'year' and 'km_driven' - to organize the data in a meaningful order.",
   "id": "272c5b9fd499ac84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare data used for regression analysis",
   "id": "a8d10f2a611467bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "features = encoded_data_sorted.columns.drop(['name', 'selling_price'])\n",
    "target = 'selling_price'\n",
    "\n",
    "X = encoded_data_sorted[features]\n",
    "y = encoded_data_sorted[target]"
   ],
   "id": "143bc2245e4d47d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block prepares the feature matrix 'X' and target vector 'Y' for training a regression model, using sorted and one-hot encoded dataset.\n",
    "1. Line1: Selects all column names except: 'name' and 'selling_price' -> Result is a list of input features for the model.\n",
    "2. Line2: Explicitly defines 'selling_price' as the target variable.\n",
    "3. Line4: Creates the feature matrix 'X' by selecting only the columns in 'features' from the dataset; 'X' will be used as input for the regression model\n",
    "4. Line5: Creates the target vector 'Y', which contains the selling prices (values to be predicted)"
   ],
   "id": "c8fb5138c428fba7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Saving test data",
   "id": "a5ad4cfd3b676531"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_data = pd.concat([X, y], axis=1)\n",
    "all_data.to_csv('prepared_used_car_data_all.csv', index=False)"
   ],
   "id": "dd2d0576a6403f24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block recombines the feature 'X' and target 'Y' into a single DataFrame and saves it as a '.csv' file for future use.\n",
    "1. Line1: Concatenates the feature matrix 'X' and the target vector 'Y' horizontally and reconstructs the full dataset 'all_data' with both inputs and outputs in one table.\n",
    "2. Line2: Saves the combined dataset to a CSV file and ensures that the DataFrame index is not written to the file, keeping the output clean and suitable for reuse."
   ],
   "id": "ec434fed0a927f84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Creation of training and test data",
   "id": "9295e915558baf12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
   "id": "5339af0b365f5a0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This line uses scikit-learn's 'train_test_split()' function to divide the dataset into training and testing subsets, a crucial step for evaluating regression models.",
   "id": "ac57a39dbe4f2d0a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Saving of training data",
   "id": "787270178633509a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv('prepared_used_car_data_train.csv', index=False)"
   ],
   "id": "a1fe4ed740f72b0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This block combines the training features and labels into a single DataFrame and then exports it to a '.csv' file for storage or reuse.\n",
    "1. Line1: Merges the training input features 'X_train' and then training target values 'Y_train' side by side (along columns) and produces a single DataFrame 'train_data' that contains all the necessary data for training a model.\n",
    "2. Line2: Saves the 'train_data' DataFrame as a CSV file and ensures the row indices are not written into the file, keeping it clean and easy to reload."
   ],
   "id": "6c121e4e808da1e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Saving of test data",
   "id": "b48b9753e3c5bed5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv('prepared_used_car_data_test.csv', index=False)"
   ],
   "id": "71fd609e140c0831"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This code combines the test features and labels into a single DataFrame and then saves it as a CSV file for future use or evaluation.\n",
    "1. Line1: Merges the test feature set 'X_test' and the corresponding target values 'Y_test' horizontally and produces a new DataFrame 'test_data' that includes all the columns needed to evaluate a regression model.\n",
    "2. Line2: Saves the resulting test dataset to a CSV file and prevents the row index from being included in the file, making the CSV clean and readable."
   ],
   "id": "d7b18279d9abcd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Confirming saved files",
   "id": "340e500960290d4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\nTrainingsdaten gespeichert als 'prepared_used_car_data_train.csv'\")\n",
    "print(\"Testdaten gespeichert als 'prepared_used_car_data_test.csv'\")"
   ],
   "id": "79d07b7563dceaab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These print statements simply confirm to the user that the training and test datasets have been successfully saved to CSV files.\n",
    "1. Line1: Outputs a message confirming that the training data was saved.\n",
    "2. Line2: Confirms that the test data was also saved."
   ],
   "id": "5bf4c8dfd38c977d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
