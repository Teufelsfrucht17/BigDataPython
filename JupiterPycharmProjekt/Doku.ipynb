{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf3680e1a6df4c9",
   "metadata": {},
   "source": [
    "# Big Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dabb562aa9b3a9",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6727a8fa07795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataPrep\n",
    "import OLS_Regression\n",
    "import Ridge_Regression\n",
    "import SVR\n",
    "import NeuralNetworks\n",
    "import RandomForest\n",
    "import KNN\n",
    "\n",
    "print(DataPrep.report)\n",
    "import DataPrep\n",
    "\n",
    "import JupiterPycharmProjekt.OLS_Regression\n",
    "import JupiterPycharmProjekt.Ridge_Regression\n",
    "import JupiterPycharmProjekt.SVR\n",
    "import JupiterPycharmProjekt.NeuralNetworks\n",
    "import JupiterPycharmProjekt.RandomForest\n",
    "import JupiterPycharmProjekt.KNN\n",
    "\n",
    "print(DataPrep.report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e442bc24151843d4",
   "metadata": {},
   "source": [
    "This block executes all model training and evaluation scripts, collects their results and prints the final comparison report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75501c1bdf61f70",
   "metadata": {},
   "source": [
    "## Data Preparation  gerne nochmal checken glaube haben dort einiges verändert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b2b11019ed5c3",
   "metadata": {},
   "source": [
    "### General\n",
    "In this section the environment for Data Preparation is set up by importing essential Python libraries. Each library plays a key role for the Data Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8972a9db816a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05def101079fdb3",
   "metadata": {},
   "source": [
    "pandas:             Used for handling and analyzing structured data\n",
    "\n",
    "matplotlib.pyplot:  A fundamental plotting library.\n",
    "\n",
    "seaborn:            Built on top of matplotlib and simplifies the process of graphical statistics.\n",
    "\n",
    "sklearn.model_selection + train_test_split: Helps to split a dataset into training and test dataset.\n",
    "\n",
    "sklearn.preprocessing + LabelEncoder: Transforming data before feeding it into a model.\n",
    "\n",
    "numpy: Is the foundational package for numerical computing in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b03ee3728e4444",
   "metadata": {},
   "source": [
    "### Read original data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e7d47459c1d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('UsedCarSellingPrices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1275f6a59584826",
   "metadata": {},
   "source": [
    "This code uses pandas to read the CSV file \"Used Car Selling Prices\" and loads it into a dataframe called 'data'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca57ba84a5a98",
   "metadata": {},
   "source": [
    "### Label-Encoding for Visualisation before cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e48d7f80daa9de",
   "metadata": {},
   "source": [
    "#### Define columns that need to be lable-encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a721af1a27119",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a160792dae95fc",
   "metadata": {},
   "source": [
    "This line defines a list of column names that represent categorical features in the dataset.\n",
    "\n",
    "fuel: type of fuel that is used by the car\n",
    "\n",
    "seller_type: type of car seller\n",
    "\n",
    "transmission: type of gear\n",
    "\n",
    "owner: status of ownership"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0568723c837ec",
   "metadata": {},
   "source": [
    "#### Copy data into var label_encoded_data; create empty array lable_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc316de039f21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded_data = data.copy()\n",
    "label_encoders = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75c88b965669d5",
   "metadata": {},
   "source": [
    "This code sets up the environment for label encoding.\n",
    "\n",
    "Line1: Copying the dataset\n",
    "\n",
    "Line2: Initializing the Encoders Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515da396df78c06",
   "metadata": {},
   "source": [
    "#### Run lable-encoder for every previosly defined columne (function imported from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92396d934e28d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded_data[col] = le.fit_transform(label_encoded_data[col])\n",
    "    label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "print(\"\\nLabel-Encoded Data for Visualisation:\")\n",
    "print(label_encoded_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fecd8ff6cc49431",
   "metadata": {},
   "source": [
    "This loop iterates over each categorical column and applies Label Encoding transforming string labels into numeric codes.\n",
    "\n",
    "1. for col in categorical_columns: Loops through each column listed earlier\n",
    "2. le = labelEncoder(): Creates a new LabelEncoder instance from scikit-learn for the current column\n",
    "3. label_encoded_data[col] = le.fit_transform(label_encoded_data[col]): Fits the encoder to the column's categories and transforms them into integers + Replaces the original text values in label_encoded_data with the corresponding numeric labels\n",
    "4. label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_))): Stores the mapping of original category names to their encoded values in the label_encoders dictionary + This allows to trace or reverse the encoding later if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4fb006cbf3b865",
   "metadata": {},
   "source": [
    "#### concatinates x and y into one point to be visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375ebafb2613c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LableEncoded = pd.concat([label_encoded_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7984b3a89fbfec",
   "metadata": {},
   "source": [
    "This line creates a new DataFrame called 'all_data_LableEncoded' by concatenating 'label_encoded_data' along the column axis 'axis=1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e31beaca0636e",
   "metadata": {},
   "source": [
    "#### Drops all columes that are non-numeric to make scaling possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c96f2c72f3a5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LableEncoded = all_data_LableEncoded.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ddeb3e01426c4",
   "metadata": {},
   "source": [
    "This line filters the dataset to keep only the numeric columns from 'all_data_LableEncoded'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12bd3a7f800f5d",
   "metadata": {},
   "source": [
    "#### Scale data (normalized via MinMaxScaler - between 0 and 1)\n",
    "sscaler = preprocessing.StandardScaler()    ???\n",
    "\n",
    "all_data_LableEncoded = sscaler.fit_transform(all_data_LableEncoded)    ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75a73ea660129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nscaler = preprocessing.MinMaxScaler()\n",
    "all_data_LableEncoded = nscaler.fit_transform(all_data_LableEncoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae25a6e0d894e17",
   "metadata": {},
   "source": [
    "This block performs Min-Max Scaling on the numeric features in the dataset, transforming them into a commonscale between 0 and 1.\n",
    "1. Line1: Initalizes a MinMaxScaler object from scikit-learn\n",
    "2. Line2: Calculates the min and max values for each feature iin the dataset and applies the scaling transformation to each value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cc9b27675b657",
   "metadata": {},
   "source": [
    "### Visualisation before cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08f375a59ed8a0",
   "metadata": {},
   "source": [
    "#### Reintegrates Column name for boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff4042b4b9c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(all_data_LableEncoded, columns=label_encoded_data.select_dtypes(include='number').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb9b3a7289d56f",
   "metadata": {},
   "source": [
    "This line converts the scaled NumPy array (from the Min-Max Scaler) back into a pandas DataFrame and restores the original column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a72bd7c435c8b",
   "metadata": {},
   "source": [
    "#### Boxplot with readable x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c04c0b96869e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=scaled_df, orient='v', palette='Set2')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Normed boxplot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead6b42ead1e6a49",
   "metadata": {},
   "source": [
    "This block creates a boxplot for each feature in the 'scaled_df' DataFrame to visualize the distribution and spread of the normalized (Min-max scaled) data.\n",
    "1. Line1: Sets the size of the figure to be 12 inches wide by 6 inches tall and ensures the plot is large enough to accommodate all features without crowding.\n",
    "2. Line2: Creates a vertical boxplot for each column in the 'scaled_df' DataFrame and uses Seaborn's elegant and color-friendly 'Set2' palette. Each box shows the median, the IQR and Whiskers & Outliers.\n",
    "3. Line3: Rotates the x-axis labels by 45 degrees for better readability, especially when there are many features.\n",
    "4. Line4: Adds a title to the plot for context, signaling that the data is normalized.\n",
    "5. Line5: Adjusts spacing to prevent overlap between axis labels, titles, and plot content.\n",
    "6. Line6: Renders and displays the final plot in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0974975b2686d02",
   "metadata": {},
   "source": [
    "#### Boxplot for only numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e149b8d9268ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['selling_price', 'km_driven', 'year']\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=scaled_df[selected_cols], orient='v', palette='Set3')\n",
    "plt.title(\"Normed boxplot for numerical data only\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb891a4313a2a18b",
   "metadata": {},
   "source": [
    "This blocks generates a boxplot visualization focused on three specific, scaled numerical features:\n",
    "\n",
    "'selling_price'\n",
    "\n",
    "'km_driven'\n",
    "\n",
    "'year'\n",
    "\n",
    "1. Line1: Selects the subset of important numerical features for focused analysis.\n",
    "2. Line2: Sets the plot size to be 8 inches wide and 5 inches tall.\n",
    "3. Line3: Creates a vertical boxplot for just the selected columns using the soft, pastel 'Set3' color palette from Seaborn.\n",
    "4. Line4: Adds a descriptive title to clarify that this plot shows normalized (scaled) numerical features.\n",
    "5. Line5: Ensures layout is adjusted for neatness and then displays the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528da982deb168c1",
   "metadata": {},
   "source": [
    "#### Pairplot to show correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc536eb1a2bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(scaled_df[selected_cols])\n",
    "plt.suptitle(\"Pairplot for select charactaristics\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e8aa1560acaa0",
   "metadata": {},
   "source": [
    "This blocks creates a pairplot to visually explore pairwise relationships among the selected numerical features:\n",
    "\n",
    "'selling_price'\n",
    "\n",
    "'km_driven'\n",
    "\n",
    "'year'\n",
    "\n",
    "1. Line1: Creates a grid of scatterplots for each pairwise combination of the selected features. This helps to visualize Correlations, Clustering tendencies and Linearity or Non-Linearity Relationships. The Histograms are shown on the diagonal to represent each variable's distribution.\n",
    "2. Line2: Adds a super title above the entire plot grid.\n",
    "3. Line3: Renders the entire pairplot for viewing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f778ecab77450",
   "metadata": {},
   "source": [
    "### Clean Data & Create variable Brand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f6e7a09542f39",
   "metadata": {},
   "source": [
    "#### Remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478576eb668d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb30eeafdc41003",
   "metadata": {},
   "source": [
    "This line removes all rows with missing values from the 'data' DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9361739167ddf637",
   "metadata": {},
   "source": [
    "#### Show how much data was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723ea92f78c504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data after removing data:\")\n",
    "print(data.isnull().sum())\n",
    "print(f\"Remaining rows: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320d64febbb147b",
   "metadata": {},
   "source": [
    "This block checks and confirms that all missing values have been removed from the dataset and reports the number of remaining rows.\n",
    "\n",
    "1. Line1: Prints a header to indicate that the following output relates to the cleaned dataset.\n",
    "2. Line2: Checks for missing values in each column of the 'data' DataFrame, creates a Boolean mask of the same shape as the data and then counts the number of 'True' values in each column, i.e. the number of missing entries.\n",
    "3. Line3: Prints the total number of rows left in the dataset after dropping rows with missing values using 'len(data)'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13c2d862a9c841",
   "metadata": {},
   "source": [
    "#### IQR-based Removal of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d64ddee25c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = np.percentile(df[column], 25)\n",
    "    Q3 = np.percentile(df[column], 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808fb431c2c8ca37",
   "metadata": {},
   "source": [
    "This function removes outliers from a specific column in a DataFrame using the Interquartile Range (IQR) method\n",
    "\n",
    "1. 'Q1': 25th percentile - the value below which 25% of the data falls\n",
    "2. 'Q3': 75th percentile - the value below which 75% of the data falls\n",
    "3. 'IQR = Q3-Q1': IQR is the spread of the middle 50% of values and it is used to understand the natural range of variation in the data.\n",
    "4. Line5 + Line6: These define the acceptable range and any values below the lower bound or above the upper bound are considered outliers.\n",
    "5. Line7: Returns a filtered version of the original DataFrame, keeping only the rows where the specified column's value is within the acceptable range -> Outlier are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bfcaa9e510db9c",
   "metadata": {},
   "source": [
    "#### Apply to most important column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc179ef93d798956",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_outliers_iqr(data, 'selling_price')\n",
    "data = remove_outliers_iqr(data, 'km_driven')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99f03f1ca00747",
   "metadata": {},
   "source": [
    "These lines apply the IQR-based outlier removal function to two important columns in the dataset: 'selling_price' and 'km_driven'.\n",
    "\n",
    "1. Line1: Removes rows where 'selling_price' is considered an outlier based on the IQR rule and keeps only cars with selling prices within the typical range.\n",
    "2. Line2: Applies the same IQR filtering to the 'km_driven' column and eliminates unusually low or high mileage entries that could distort statistical analysis or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b00c4db8c02c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDaten nach IQR-basierter Ausreißerbereinigung:\")\n",
    "print(f\"Max. Verkaufspreis: {data['selling_price'].max()}\")\n",
    "print(f\"Max. Kilometerstand: {data['km_driven'].max()}\")\n",
    "print(f\"Verbleibende Zeilen nach IQR-Filter: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3eeed17c51636",
   "metadata": {},
   "source": [
    "This block prints a quick summary of the dataset after removing outliers using the IQR method.\n",
    "1. Line1: Prints a headline used for clarity when reading the console output.\n",
    "2. Line2: Displays the maximum selling price in the cleaned dataset which helps verifying that extremely high prices have been removed.\n",
    "3. Line3: Shows the maximum odometer reading after outlier removal and ensures that unusally high mileage values have been filtered out.\n",
    "4. Line4: Prints the number of remaining rows in the dataset which tells how much data is left after removing rows that contained outliers in 'selling_price' and 'km_driven'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bf4ed9e5eac31",
   "metadata": {},
   "source": [
    "#### Create 'Brand' as new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35fe3e1026f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['brand'] = data['name'].str.split().str[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edce02663cc2c28",
   "metadata": {},
   "source": [
    "This line creates a new column called 'brand' by extracting the first word from the 'name' column which represents the car brand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a160b07af3d056",
   "metadata": {},
   "source": [
    "### Label-Encoding for Visualisation after cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58975c2852af76",
   "metadata": {},
   "source": [
    "#### ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3670cbf0cfa6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['fuel', 'seller_type', 'transmission', 'owner']\n",
    "label_encoded_data = data.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded_data[col] = le.fit_transform(label_encoded_data[col])\n",
    "    label_encoders[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "print(\"\\nLabel-Encoded Data (nur zur Referenz):\")\n",
    "print(label_encoded_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad31c9e1922f96",
   "metadata": {},
   "source": [
    "This block performs label encoding on selected categorical columns, converting them from text values to integers so they can be used in regression models.\n",
    "\n",
    "1. Line1: Specifies the list of categorical features to be encoded which are typically textual descriptors that must be converted into numeric format for modeling.\n",
    "2. Line2: Creates a copy of the original dataset to apply the encodings without altering the raw data.\n",
    "3. Line3: Initializes an empty dictionary to store the encoding mappings for each categorical column.\n",
    "4. The 'for' loop: Iterates over each column in the 'categorical_columns' list; The 'LabelEncoder()' from scikit-learn is used to convert category labels into integers. The transformed values replace the original column in 'label_encoded_data'. The mapping of original class labels to integer codes is stored in 'label_encoders' for reference or inverse transformation later.\n",
    "5. Line10 + Line11: Displays the first few rows of the updated dataset to confirm that the categorical features have been encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f74c3b81afbcc",
   "metadata": {},
   "source": [
    "#### concatinate x and y into one point to be visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90feb61d4cc86b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LableEncoded = pd.concat([label_encoded_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f631765aeb1c740",
   "metadata": {},
   "source": [
    "This line creates a new DataFrame called 'all_data_LableEncoded' by concatenating the contents of 'label_encoded_data' along the columns axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a033f688a670b2a",
   "metadata": {},
   "source": [
    "#### Drop all columns that are non-numeric to make scaling possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534cde6690518511",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LableEncoded = all_data_LableEncoded.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f1545a3b99ad3",
   "metadata": {},
   "source": [
    "This line filters the 'all_data_LableEncoded' DataFrame to include only numeric columns, removing any that are not numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07c06cb19fef75",
   "metadata": {},
   "source": [
    "#### Scale data (normalized)\n",
    "\n",
    "sscaler = preprocessing.StandardScaler()\n",
    "\n",
    "all_data_LableEncoded = sscaler.fit_transform(all_data_LableEncoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec105be81b324dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nscaler = preprocessing.MinMaxScaler()\n",
    "all_data_LableEncoded = nscaler.fit_transform(all_data_LableEncoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24f8339d565fba",
   "metadata": {},
   "source": [
    "This code applies Min-Max Scaling to normalize all numeric features in the dataset, transforming their values to a common range between 0 and 1.\n",
    "1. Line1: Initializes a MinMaxScaler object from scikit-learn's 'preprocessing' module and will scale each feature individually.\n",
    "2. Line2: Calculates the minimum and maximum values for each feature and scales each value in the dataset to the 0-1 range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e221dbf855a14d",
   "metadata": {},
   "source": [
    "### Visualization after Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27b50893bcf74b",
   "metadata": {},
   "source": [
    "#### Scale Data ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db41f2efeda0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = pd.DataFrame(all_data_LableEncoded, columns=label_encoded_data.select_dtypes(include='number').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9c5d0affc2cc",
   "metadata": {},
   "source": [
    "This line converts the scaled NumPy array back into a pandas DataFrame and restores the original column names, making the data human-readable and easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e216caa2154a2",
   "metadata": {},
   "source": [
    "#### 1. Boxplot with readable axis names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4be1f0e93359fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=scaled_df, orient='v', palette='Set2')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot der skalierten numerischen Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94c98254259a59",
   "metadata": {},
   "source": [
    "This block creates a boxplot for all features in the 'scaled_df' DataFrame, which contains only scaled numeric data. The plot helps visually inspecting the distribution and variability of each feature.\n",
    "1. Line1: Sets the figure size to 12 inches wide by 6 inches tall for better readability.\n",
    "2. Line2: Uses Seaborn to draw vertical boxplots for each numeric feature in 'scaled_df' and 'palette=Set2' gives the plot a soft, color-coded appearance to distinguish features visually.\n",
    "3. Line3: Rotates the x-axis labels by 45 degrees so that long feature names dont overlap and remain legible.\n",
    "4. Line4: Adds a descriptive title\n",
    "5. Line5 + Line6: Adjusts the layout to avoid overlapping elements and displays the final plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372e0ea45e7af3",
   "metadata": {},
   "source": [
    "#### 2. Boxplot only for selected numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572d28726daa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['selling_price', 'km_driven', 'year']\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=scaled_df[selected_cols], orient='v', palette='Set3')\n",
    "plt.title(\"Boxplot ausgewählter Merkmale\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2798ae873fb6d6b",
   "metadata": {},
   "source": [
    "This block creates a boxplot visualization for a selected subset of key numeric features: 'selling_price', 'km_driven' and 'year', all of which have been previously scaled to 0-1 range.\n",
    "1. Line1: Selects the three features for targeted visualization.\n",
    "2. Line2: Sets the figure size to 8 inches wide and 5 inches tall for compact clarity.\n",
    "3. Line3: Draws vertical boxplots for just the selected columns using Seaborn's pastel 'Set3' color palette.\n",
    "4. Line4: Adds a title.\n",
    "5. Line5 + Line6: Adjusts spacing to prevent overlap and displays the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ca5a17e95eb62",
   "metadata": {},
   "source": [
    "#### 3. Pairplot for Distribution and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5546675dd85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(scaled_df[selected_cols])\n",
    "plt.suptitle(\"Paarweise Verteilungen ausgewählter Merkmale\", y=1.02)\n",
    "plt.show()\n",
    "#print(\"Trainingsdaten zusätzlich als 'prepared_used_car_data_train.parquet' gespeichert.\")\n",
    "#print(\"Testdaten zusätzlich als 'prepared_used_car_data_test.parquet' gespeichert.\")\n",
    "#print(\"Gesamtdaten zusätzlich als 'prepared_used_car_data.parquet' gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4cd0eb232d81c",
   "metadata": {},
   "source": [
    "This block creates a pairplot that visualizes the pairwise relationships and distributions of three selected, scaled features: 'selling_price', 'km_driven' and 'year'.\n",
    "1. Line1: Generates a grid of plots: Scatter plots and Histograms.\n",
    "2. Line2: Adds a descriptive title above the plot grid; 'y=1.02' adjusts the title position slightly above the plot area to prevent overlap.\n",
    "3. Line3: Renders and displays the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34beaaa83dfb659d",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding for Regression Model Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424611b424910f08",
   "metadata": {},
   "source": [
    "#### One-Hot-Encoding for categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3632ce25d57c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncoded_data = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(\"\\nOne-Hot-Encoded Data:\")\n",
    "print(encoded_data.head())\n",
    "\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a0d41d69124fa9",
   "metadata": {},
   "source": [
    "This block uses one-hot encoding to transform categorical columns in the dataset into binary 0 or 1 columns, making them suitable for regression models.\n",
    "1. Line1: Performs one-hot encoding on the columns listed in 'categorical_columns'. For each unique category in these columns, new binary columns are created. Drops the first category for each column to avoid multicollinearity when using models like linear regression.\n",
    "2. Line3: Prints a header for clarity in console output.\n",
    "3. Line4: Displays the first few rows of the encoded dataset for a quick preview.\n",
    "4. Line6: Prints the entire DataFrame, which now contains both numeric and one-hot encoded binary columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c04d61d9b69e1",
   "metadata": {},
   "source": [
    "### Sort data by 'year' and 'km_driven'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29562d18d8eab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_sorted = encoded_data.sort_values(by=['year', 'km_driven'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b2c20ee3fda993",
   "metadata": {},
   "source": [
    "This line sorts the encoded dataset based on two columns - 'year' and 'km_driven' - to organize the data in a meaningful order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c866911a853cd2",
   "metadata": {},
   "source": [
    "### Prepare data used for regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967234d07de09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = encoded_data_sorted.columns.drop(['name', 'selling_price'])\n",
    "target = 'selling_price'\n",
    "\n",
    "X = encoded_data_sorted[features]\n",
    "y = encoded_data_sorted[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b181cbc9a123a0",
   "metadata": {},
   "source": [
    "This block prepares the feature matrix 'X' and target vector 'Y' for training a regression model, using sorted and one-hot encoded dataset.\n",
    "1. Line1: Selects all column names except: 'name' and 'selling_price' -> Result is a list of input features for the model.\n",
    "2. Line2: Explicitly defines 'selling_price' as the target variable.\n",
    "3. Line4: Creates the feature matrix 'X' by selecting only the columns in 'features' from the dataset; 'X' will be used as input for the regression model\n",
    "4. Line5: Creates the target vector 'Y', which contains the selling prices (values to be predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bae775de587331",
   "metadata": {},
   "source": [
    "#### Saving test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487581c01f6a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([X, y], axis=1)\n",
    "all_data.to_csv('prepared_used_car_data_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5595b313fc27d5",
   "metadata": {},
   "source": [
    "This block recombines the feature 'X' and target 'Y' into a single DataFrame and saves it as a '.csv' file for future use.\n",
    "1. Line1: Concatenates the feature matrix 'X' and the target vector 'Y' horizontally and reconstructs the full dataset 'all_data' with both inputs and outputs in one table.\n",
    "2. Line2: Saves the combined dataset to a CSV file and ensures that the DataFrame index is not written to the file, keeping the output clean and suitable for reuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ae433862329da",
   "metadata": {},
   "source": [
    "#### Creation of training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c67feaf5f924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e917ccd7fedec",
   "metadata": {},
   "source": [
    "This line uses scikit-learn's 'train_test_split()' function to divide the dataset into training and testing subsets, a crucial step for evaluating regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658474144423a97",
   "metadata": {},
   "source": [
    "#### Saving of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1134ca92ea2ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv('prepared_used_car_data_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b767072458240",
   "metadata": {},
   "source": [
    "This block combines the training features and labels into a single DataFrame and then exports it to a '.csv' file for storage or reuse.\n",
    "1. Line1: Merges the training input features 'X_train' and then training target values 'Y_train' side by side (along columns) and produces a single DataFrame 'train_data' that contains all the necessary data for training a model.\n",
    "2. Line2: Saves the 'train_data' DataFrame as a CSV file and ensures the row indices are not written into the file, keeping it clean and easy to reload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9c1209c27c6b8",
   "metadata": {},
   "source": [
    "#### Saving of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecb1a8e5800d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv('prepared_used_car_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417829164c3d2d9",
   "metadata": {},
   "source": [
    "This code combines the test features and labels into a single DataFrame and then saves it as a CSV file for future use or evaluation.\n",
    "1. Line1: Merges the test feature set 'X_test' and the corresponding target values 'Y_test' horizontally and produces a new DataFrame 'test_data' that includes all the columns needed to evaluate a regression model.\n",
    "2. Line2: Saves the resulting test dataset to a CSV file and prevents the row index from being included in the file, making the CSV clean and readable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53fcc1b31f27a5f",
   "metadata": {},
   "source": [
    "#### Confirming saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ab05b37ea8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrainingsdaten gespeichert als 'prepared_used_car_data_train.csv'\")\n",
    "print(\"Testdaten gespeichert als 'prepared_used_car_data_test.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728efe85e240e7f",
   "metadata": {},
   "source": [
    "These print statements simply confirm to the user that the training and test datasets have been successfully saved to CSV files.\n",
    "1. Line1: Outputs a message confirming that the training data was saved.\n",
    "2. Line2: Confirms that the test data was also saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913fdd0c6b08df1f",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36d85c8da1450c",
   "metadata": {},
   "source": [
    "#### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b1e9da195258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import DataPrep\n",
    "\n",
    "(X_train_KNN, X_test_KNN, Y_train_KNN, Y_test_KNN) = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88890b73da1c3e46",
   "metadata": {},
   "source": [
    "This block sets upo the environment to train and evaluate a K-Nearest Neighbors Regression model using a train/test split of preprocessed data.\n",
    "\n",
    "1. Line1: Imports the KNN regressor from scikit-learn\n",
    "2. Line2: Adds a tool for hyperparameter tuning by trying different values and splits the dataset into training and testing sets\n",
    "3. Line3: Imports the DataPrep file\n",
    "4. Line5: Splits features and target into a training set and testing set while ensuring that the split is reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f94c4c912cc921",
   "metadata": {},
   "source": [
    "#### Initialize KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294d053ab7fc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnmodelCV = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87886d8e6cbaffdc",
   "metadata": {},
   "source": [
    "This line creates an instance of the KNN model from scikit-learn with default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7565349b274051ba",
   "metadata": {},
   "source": [
    "#### Define grid of neighbor counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6f8cb0f3ca853",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'n_neighbors': range(3, 22, 2),\n",
    "'weights': ['uniform', 'distance'],\n",
    "'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "'leaf_size': [8, 16, 32, 64, 128, 256, 512],\n",
    "'p': [2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa17ca71204c291",
   "metadata": {},
   "source": [
    "This block defines a hyperparameter grid that will be used to tune a KNN regressor using tools like GridSearchCV.\n",
    "\n",
    "1. Line2: Tries odd values for k from 3 to 21 which defines how many neighbors the model considers when making predictions.\n",
    "2. Line3: 'uniform' makes sure all neighbors contribute equally to the prediction and 'distance' makes sure that closer neighbors contribute more to the prediction than distant ones.\n",
    "3. Line4: Specifies the search algorithm used to find neighbors. 'auto' -> Chooses the best algorithm based on the data. 'ball_tree' and 'kd_tree' -> Use tree structure for fast searches. 'brute' -> Calculates distances directly.\n",
    "4. Line5: Affects the speed vs. memory tradeoff in tree based algorithms. Smaller values result in faster query time. Larger values result in faster tree building.\n",
    "5. Line6: Specifies the power parameter for the Minkowski distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc98717ded8420",
   "metadata": {},
   "source": [
    "#### Run 10-fold cross-validation across neighbor settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ed5930d7a7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_knnmodel = GridSearchCV(estimator=knnmodelCV, param_grid=param_grid, cv=10,n_jobs=-1)\n",
    "CV_knnmodel.fit(X_train_KNN, Y_train_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e884a5c287dd7b7",
   "metadata": {},
   "source": [
    "This code uses GridSearchCV from scikit-learn to perform an exhaustive search over a defined set of hyperparameters for a KNN regression model.\n",
    "Assigns all available CPU cores to parallelize the search and speed up computation and uses 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7a16cecfb1ef",
   "metadata": {},
   "source": [
    "#### Output the best number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08d576e3bc342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found:\", CV_knnmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23271a575ac5ca71",
   "metadata": {},
   "source": [
    "This line prints the optimal set of hyperparameters that were found during the GridSearchCV process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba83f7b6489e0",
   "metadata": {},
   "source": [
    "#### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d1ff7e08dbfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_knnmodel.predict(X_train_KNN)\n",
    "Y_train_dev = sum((Y_train_KNN - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_KNN - Y_train_KNN.mean())**2)\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad2e436bf95347",
   "metadata": {},
   "source": [
    "This block manually calculates the coefficient of determination (r2) to evaluate how well the KNN model fits the training data.\n",
    "1. Line1: Uses the trained cross-validated KNN model to predict selling prices for the training set.\n",
    "2. Line2: Calculates the residual sum of squares (RSS) and measures how far off the predictions are from the actual values which should be minimal.\n",
    "3. Line3: Calculates the total sum of squares (TSS) and measures the total variation in the target variable (how far are values from the mean)\n",
    "4. Line4: Calculates the coefficient of determination (r2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe85c50a2cfb01",
   "metadata": {},
   "source": [
    "#### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9f4fdd36f8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_knnmodel.predict(X_test_KNN)\n",
    "Y_test_dev = sum((Y_test_KNN - Y_test_pred)**2)\n",
    "Y_test_meandev = sum((Y_test_KNN - Y_test_KNN.mean())**2)\n",
    "pseudor2 = 1 - Y_test_dev / Y_test_meandev\n",
    "\n",
    "DataPrep.report.loc[len(DataPrep.report)] = [\"KNN_LE \", r2, pseudor2,\"\", CV_knnmodel.cv_results_['mean_test_score'][CV_knnmodel.best_index_], CV_knnmodel.cv_results_['std_test_score'][CV_knnmodel.best_index_]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9353e03545b53f1",
   "metadata": {},
   "source": [
    "This block evaluates the KNN model on the test set using the coefficient of determination and calculates a pseudo r2 score for generalization performance and appends a summary row to report DataFrame for later comparison with other models.\n",
    "1. Line1: Uses the best tuned KNN model to predict the selling prices for the test set.\n",
    "2. Line2: Calculates the residual sum of squares (RSS) on the test data.\n",
    "3. Line3: Computes the total sum of squares (TSS) of the actual test values\n",
    "4. Line4: Calculates pseudo-r2 which is the models explanatory power on the unseen test data.\n",
    "5. Line6: Logs results to a report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32ccb1e13d0a21",
   "metadata": {},
   "source": [
    "#### Splitting One-Hot Encoded Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83765b9d7b1f833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_KNN, X_test_KNN, Y_train_KNN, Y_test_KNN) = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ba6eca30b9ed3",
   "metadata": {},
   "source": [
    "This line splits the one-hot encoded dataset into training and testing sets for building and evaluating a KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca064ee8b924495d",
   "metadata": {},
   "source": [
    "#### Run 10-fold cross-validation across neighbor settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb112676327e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_knnmodel = GridSearchCV(estimator=knnmodelCV, param_grid=param_grid, cv=10,n_jobs=-1)\n",
    "CV_knnmodel.fit(X_train_KNN, Y_train_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582037eb7717b901",
   "metadata": {},
   "source": [
    "This block performs hyperparameter optimization for the KNN regression model using one-hot encoded data with cross validation to ensure reliable model selection.\n",
    "1. Line1: Performs an exhaustive grid search over the parameter combinations defined in 'param_grid'.\n",
    "2. Line2: Trains and evaluates all hyperparameter combinations using the training data based on one-hot encoded features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30201764aec89c",
   "metadata": {},
   "source": [
    "#### Output the best number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43f95c135b9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found:\", CV_knnmodel.best_params_)\n",
    "Y_train_pred = CV_knnmodel.predict(X_train_KNN)\n",
    "Y_train_dev = sum((Y_train_KNN - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_KNN - Y_train_KNN.mean())**2)\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831cd79491d672da",
   "metadata": {},
   "source": [
    "This line prints the optimal hyperparameter combination selected by 'GridSearchCV' for the KNN regression model trained on one-hot encoded data.\n",
    "1. Line2: Predicts the selling prices for the training data using the best-found KNN model.\n",
    "2. Line3: Computes the residual sum of squares (RSS) and measures how much error remains after using the models predictions.\n",
    "3. Line4: Computes the total sum of squares (TSS) and represents the total variance in the training labels serving as a baseline.\n",
    "4. Line5: Calculates the r2 score which explains how much variation is explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432bff5642ee100",
   "metadata": {},
   "source": [
    "#### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5880e8f8375013",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_knnmodel.predict(X_test_KNN)\n",
    "Y_test_dev = sum((Y_test_KNN - Y_test_pred)**2)\n",
    "Y_test_meandev = sum((Y_test_KNN - Y_test_KNN.mean())**2)\n",
    "pseudor2 = 1 - Y_test_dev / Y_test_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6128865347c811",
   "metadata": {},
   "source": [
    "This block evaluates how well the tuned KNN model generalizes to unseen data by manually calculating the pseudo r2 score.\n",
    "1. Line1: Uses the trained KNN model to predict selling prices for the test set.\n",
    "2. Line2: Computes the residual sum of squares (RSS) for the test set and measures the models prediction error on unseen data.\n",
    "3. Line3: Compues the total sum of squares (TSS) for the test set and represents the total variance in the actual test values serving as a baseline.\n",
    "4. Line4: Calculates the pseudo-r2 and indicates how well the model generalizes to new unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8277422d3a75cb",
   "metadata": {},
   "source": [
    "#### Log KNN Model results in a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661288c5440411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"KNN_OH \", r2, pseudor2,\"\", CV_knnmodel.cv_results_['mean_test_score'][CV_knnmodel.best_index_], CV_knnmodel.cv_results_['std_test_score'][CV_knnmodel.best_index_]]\n",
    "print(DataPrep.report.head())\n",
    "print(CV_knnmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8549bb992fcc71",
   "metadata": {},
   "source": [
    "This block logs the performance metrics of the KNN model trained with one-hot encoded data into a centralized evaluation report and then displays the report and the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0298822913ab143",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459a43857effd0f",
   "metadata": {},
   "source": [
    "#### Preparation to train a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a96d3bda5b49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import DataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea18a40661d12073",
   "metadata": {},
   "source": [
    "This block sets up the environment for training and tuning a neural network regression model using scikit-learn's 'MLPRegressor' with data and configuration coming from a shared module called 'DataPrep'.\n",
    "1. Line1: Used to split data into training and testing sets and enables hyperparameter tuning using exhaustive search with cross-validation.\n",
    "2. Line2: Imports 'MLPRegressor' a multilayer perceptron for regression tasks.\n",
    "3. Line3: Imports the 'DataPrep' module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff98b11f54bde9",
   "metadata": {},
   "source": [
    "#### Splitting Label-Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26efe58f08b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_nn, X_test_nn, Y_train_nn, Y_test_nn) = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938be294c034fd3",
   "metadata": {},
   "source": [
    "This line splits the label-encoded dataset into training and testing sets preparing it for use in training a neural network regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbc2704d7e93e0",
   "metadata": {},
   "source": [
    "#### Defining a Hyperparameter Grid for Tuning the Network Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c13350df76b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'hidden_layer_sizes': [(5,), (8,), (10,), (13,)],\n",
    "'alpha': [0.0, 0.0025, 0.005, 0.0075, 0.01, 0.1],\n",
    "'activation': ['logistic', 'tanh', 'relu'],\n",
    "'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "'max_iter': [5000],\n",
    "'random_state': [0],\n",
    "'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8259638519a2e",
   "metadata": {},
   "source": [
    "This block defines a parameter grid to be used with 'GridSearchCV' for tuning a 'MLPRegressor' model in a regression task. Each key represents a hyperparameter and each value is a list of options that 'GridSearchCV' will explore during cross-validation.\n",
    "1. Line2: Defines the structure of the hidden layers; how many neurons\n",
    "2. Line3: L2 regularization term which helps to prevent overfitting by penalizing large weights\n",
    "3. Line4: Specifies the activation function used in the hidden layers\n",
    "4. Line5: Optimization algorithm used for training\n",
    "5. Line6: Sets the maximum number of training iterations to 5000\n",
    "6. Line7: Ensures reproducibility by fixing the random seed used inernally by the model\n",
    "6. Line8: Controls how the learning rate adapts over time when using 'sgd' or 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b317525d6e67e84",
   "metadata": {},
   "source": [
    "#### Training a Neural Network with Grid Search and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0102299ad7865d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNetRregCV = MLPRegressor()\n",
    "CV_nnmodel = GridSearchCV(estimator=NNetRregCV, param_grid=param_grid, cv=10,n_jobs=-1)\n",
    "CV_nnmodel.fit(X_train_nn, Y_train_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed941239c09b3d13",
   "metadata": {},
   "source": [
    "This block creates, tunes and trains a neural network regressor using scikit-learn's 'MLPRegressor' and 'GridSearchCV'.\n",
    "1. Line1: Initializes a Multi-Layer Perceptron (MLP) Regressor which is a type of feedforward neural network.\n",
    "2. Line2: Wraps the neural network model with 'GridSearchCV' to perform automated hyperparameter tuning.\n",
    "3. Line3: Trains the model using the training data and runs the grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15928d9333a02d79",
   "metadata": {},
   "source": [
    "#### Evaluating the Neural Network on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c478d8829a7dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_nnmodel.predict(X_train_nn)\n",
    "Y_train_dev = sum((Y_train_nn - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_nn - Y_train_nn.mean())**2)  # [aus PDF]\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223243634634b44",
   "metadata": {},
   "source": [
    "This block manually calculates the r2 score to evaluate how well the trained neural network model fits the training data.\n",
    "1. Line1: Uses the best neural network model selected by 'GridSearchCV' to predict target values for the training set\n",
    "2. Line2: Calculates the residual sum of squares (RSS) and measures the total prediction error of the model\n",
    "3. Line3: Calculates the total sum of squares (TSS) and measures how much variance is in the target data without any model\n",
    "4. Line4: Computes the r2 score which explains the variance in the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d660e23601c4437",
   "metadata": {},
   "source": [
    "#### Evaluating the Neural Network on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebea710b755b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_nnmodel.predict(X_test_nn)\n",
    "Y_test_dev = sum((Y_test_nn - Y_test_pred)**2)\n",
    "Y_train_meandev = sum((Y_test_nn - Y_test_nn.mean())**2)  # [aus PDF]\n",
    "pseudor2 = 1 - Y_test_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b89b249790996e",
   "metadata": {},
   "source": [
    "This block calculates the pseudo r2 score to assess how well the trained neural network regressor performs on unseen test data.\n",
    "1. Line1: Predicts target values for the test set using the neural network model selected by 'GridSearchCV'\n",
    "2. Line2: Computes the residual sum of squares (RSS) for the test set which represents the total prediction error of the model on unseen data\n",
    "3. Line3: Computes the total sum of squares (TSS) for the test set which represents the total variance in the target values\n",
    "4. Line4: Calculates the pseudo r2 score used to evaluate the model performance on the test data by measuring how much variability in the test target data is explained by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f7d6571abd4c8",
   "metadata": {},
   "source": [
    "#### Logging Neural Network Results into the Model Comparison Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4cf16056238160",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"NN_LE \", r2, pseudor2,\"\", CV_nnmodel.cv_results_['mean_test_score'][CV_nnmodel.best_index_], CV_nnmodel.cv_results_['std_test_score'][CV_nnmodel.best_index_]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f229704b383866",
   "metadata": {},
   "source": [
    "This line adds a new row to the shared 'DataPrep.report' table documenting the performance metrics of the neural network model trained with label-encoded data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a680a2d62ca81d",
   "metadata": {},
   "source": [
    "#### Displaying the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f05494fbc64807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CV_nnmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cda8f9c77e2f5e",
   "metadata": {},
   "source": [
    "This line prints the optimal hyperparameter configuration found by 'GridSearchCV' during training of the MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b8a7dfa53e9c80",
   "metadata": {},
   "source": [
    "#### Splitting One-Hot Encoded Data for Neural Network Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598d422ae567bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_nn, X_test_nn, Y_train_nn, Y_test_nn) = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f6ad493efcda3",
   "metadata": {},
   "source": [
    "This line splits the dataset - specifically the one-hot encoded version - into a training set and a test set preparing it for use with a neural network regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80956590c17d9861",
   "metadata": {},
   "source": [
    "#### Grid Search to Train and Tune a Neural Network with One-Hot Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc889752ac0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_nnmodel = GridSearchCV(estimator=NNetRregCV, param_grid=param_grid, cv=10,n_jobs=-1)\n",
    "CV_nnmodel.fit(X_train_nn, Y_train_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acce970a616e7b8",
   "metadata": {},
   "source": [
    "This code performs automated hyperparameter tuning using 'GridSearchCV' for a neural network regression model trained on one-hot encoded features.\n",
    "1. Line1: Wraps the 'MLPRegressor' in a 'GridSearchCV' object to perform an exhaustive search over a grid of hyperparameters\n",
    "2. Line2: Trains the model using the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd82fe1a0c50ff",
   "metadata": {},
   "source": [
    "#### Calculating r2 score for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd612181e6e9775",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_nnmodel.predict(X_train_nn)\n",
    "Y_train_dev = sum((Y_train_nn - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_nn - Y_train_nn.mean())**2)  # [aus PDF]\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d117c4552ead93e",
   "metadata": {},
   "source": [
    "This block manually computes the r2 score for the neural network model trained on one-hot encoded features using the training dataset\n",
    "1. Line1: Predicts the target values on the training data using the best neural network selected by 'GridSearchCV'\n",
    "2. Line2: Calculates the residual sum of squares (RSS) which represents the total prediction error of the model on the training set.\n",
    "3. Line3: Calculates the total sum of squares (TSS) which represents the total variance in the training data assuming a baseline model that always predicts the mean\n",
    "4. Line4: Computes the r2 score which measures how well the model explains the variance in the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e55a4b832b76bd",
   "metadata": {},
   "source": [
    "#### Calculating pseudo r2 score for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af847fb3088b532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_nnmodel.predict(X_test_nn)\n",
    "Y_test_dev = sum((Y_test_nn - Y_test_pred)**2)\n",
    "Y_train_meandev = sum((Y_test_nn - Y_test_nn.mean())**2)  # [aus PDF]\n",
    "pseudor2 = 1 - Y_test_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316893efb4ea9d35",
   "metadata": {},
   "source": [
    "This code block calculates the r2 score on the test dataset (pseudo r2) to evaluate the generalization performance of the neural network trained on one-hot encoded features.\n",
    "1. Line1: Uses the trained neural network to predict values for the test set.\n",
    "2. Line2: Computes the residual sum of squares (RSS) on the test set and measures the total prediction error made by the model on unseen data\n",
    "3. Line3: Calculates the total sum of squares (TSS) on the test data\n",
    "4. Line4: Calculates the test r2 (pseudo r2) which reflects how well the model generalizes to new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a702d732430c9a",
   "metadata": {},
   "source": [
    "#### Logging Neural Network Results to the Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402a7e2b5bed92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"NN_OH \", r2, pseudor2,\"\", CV_nnmodel.cv_results_['mean_test_score'][CV_nnmodel.best_index_], CV_nnmodel.cv_results_['std_test_score'][CV_nnmodel.best_index_]]\n",
    "print(DataPrep.report.head())\n",
    "print(CV_nnmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f90190be154f4f",
   "metadata": {},
   "source": [
    "This block adds a new row to your 'DataPrep.report' table to document the performance of a neural network model trained on one-hot encoded features and then displays the first few rows of the report and the best hyperparameters found during grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88c6098b6e4ade",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476196c847f7f693",
   "metadata": {},
   "source": [
    "#### Importing Libraries and Project Modules for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a051e1f7bde74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import DataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100372067b7b649",
   "metadata": {},
   "source": [
    "This block imports all the necessary libraries and modules to perform linear regression modeling, evaluation and visualization - using built-in tools from 'scikit-learn' and 'DataPrep'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c621249dd17b1",
   "metadata": {},
   "source": [
    "#### Splitting label-encoded data for OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d381e8025002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OLS, X_test_OLS, Y_train_OLS, Y_test_OLS = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a117ff84daed930",
   "metadata": {},
   "source": [
    "This line splits the label-encoded dataset into training and testing sets to prepare for training a Ordinary Least Square (OLS) regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b441d091749fce51",
   "metadata": {},
   "source": [
    "#### Set model specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e81de5fae0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train_OLS, Y_train_OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643c1810ba9d289",
   "metadata": {},
   "source": [
    "This block creates and fits an Ordinary Least Square linear regression model for the training data.\n",
    "1. Line1: Initializes a new instance of 'LinearRegression' from 'scikit-learn' which assumes a linear relationship between the input features and the target variable.\n",
    "2. Line2: Fits the model on the training dataset and learns the optimal coefficients (ß) and intercept to minimize the sum of squared errors between predicted and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2794e867b18b",
   "metadata": {},
   "source": [
    "#### Prediction and Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32c0d718211a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = ols_model.predict(X_train_OLS)\n",
    "y_test_pred = ols_model.predict(X_test_OLS)\n",
    "\n",
    "r2_train = r2_score(Y_train_OLS, y_train_pred)\n",
    "r2_test = r2_score(Y_test_OLS, y_test_pred)\n",
    "\n",
    "DataPrep.report.loc[len(DataPrep.report)] = ['OLS RegressionLC', r2_train, r2_test,np.sqrt(mean_squared_error(Y_test_OLS, y_test_pred)), \"\", \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f788617dc91218",
   "metadata": {},
   "source": [
    "This block generates predictions using the OLS model, calculates performance metrics and stores the results in the model comparison report ('DataPrep.report').\n",
    "1. Line1: Predicts the target variable for the training dataset using the fitted OLS model.\n",
    "2. Line2: Predicts the target variable for the test dataset using the fitted OLS model.\n",
    "3. Line4: Calculates the coefficient of determination (r2) for the training set.\n",
    "4. Line5: Calculates the coefficient of determination (r2) for the test set.\n",
    "5. Line7: Calculates Root Mean Squared Error (RMSE) for the test set and appends a row to the 'DataPrep.report' with the model name, r2 scores, RMSE scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c2a030623d604",
   "metadata": {},
   "source": [
    "#### Residual plot based on OLS result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ebabb2844d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y_test_OLS - y_test_pred\n",
    "plt.scatter(Y_test_OLS, residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Selling price\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residual plot - OLS LE\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4d3a175b9c0a6",
   "metadata": {},
   "source": [
    "This block generates a residual plot which is a key diagnostic tool for evaluating the quality of a regression model.\n",
    "1. Line1: Calculates the residuals.\n",
    "2. Line2: Creates a scatter plot of redsiduals against the actual selling prices which helps to detect patterns that indicate model bias or non-linearity.\n",
    "3. Line3: Draws a horizontal red dashed line at residual = 0 -> representing perfect predictions; Points above the line -> underprediction; Points below the line -> overprediction\n",
    "4. Line4 - Line6: Adds axis names and proper layout\n",
    "5. Line7: Prevents overlapping elements\n",
    "6. Line8: Displays the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadecc53d4d53245",
   "metadata": {},
   "source": [
    "#### Splitting One-Hot Label Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d12e2b0256f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_OLS, X_test_OLS, Y_train_OLS, Y_test_OLS = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15723d255a161411",
   "metadata": {},
   "source": [
    "This line splits the one-hot encoded dataset into training and testing sets to prepare for training and evaluating an OLS regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e1cbc7b9dc09",
   "metadata": {},
   "source": [
    "#### Training an OLS regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee611be889f77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train_OLS, Y_train_OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0ab3759bf5080",
   "metadata": {},
   "source": [
    "This block creates and trains an OLS linear regression model using one-hot encoded features as input\n",
    "1. Line1: Initiates a new linear regression model from 'scikit-learn'\n",
    "2. Line2: Trains the model on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f94f826565933",
   "metadata": {},
   "source": [
    "#### Evaluate and log performance of OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701e608869c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = ols_model.predict(X_train_OLS)\n",
    "y_test_pred = ols_model.predict(X_test_OLS)\n",
    "\n",
    "r2_train = r2_score(Y_train_OLS, y_train_pred)\n",
    "r2_test = r2_score(Y_test_OLS, y_test_pred)\n",
    "\n",
    "DataPrep.report.loc[len(DataPrep.report)] = ['OLS RegressionOH', r2_train, r2_test,np.sqrt(mean_squared_error(Y_test_OLS, y_test_pred)), \"\", \"\"]\n",
    "\n",
    "print(DataPrep.report.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daacc13ca09ae85",
   "metadata": {},
   "source": [
    "This block generates predictions using the trained OLS model, computes performance metrics and appends the results to the centralized model comparison report.\n",
    "1. Line1: Predicts selling prices for training data using the OLS model.\n",
    "2. Line2: Predicts selling prices for test data using the OLS model.\n",
    "3. Line4: Calculates the coefficient of determination (r2) for the training set.\n",
    "4. Line5: Calculates the coefficient of determination (r2) for the test set.\n",
    "5. Line7: Calculates Root Mean Squared Error (RMSE) for the test set and appends a row to the 'DataPrep.report' with the model name, r2 scores, RMSE scores.\n",
    "6. Line9: Displays the first few rows of the report to confirm logging was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26983cfe8de8409e",
   "metadata": {},
   "source": [
    "#### Residual plot for OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166b12092d2864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y_test_OLS - y_test_pred\n",
    "plt.scatter(Y_test_OLS, residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Selling price\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residual plot - OLS OH\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20014338692afd0",
   "metadata": {},
   "source": [
    "This block creates a residual plot to visualize the prediction errors of the OLS regression model trained on one-hot encoded data.\n",
    "1. Line1: Calculates the residuals\n",
    "2. Line2: Creates a scatter plot of redsiduals against the actual selling prices which helps to detect patterns that indicate model bias or non-linearity.\n",
    "3. Line3: Draws a horizontal red dashed line at residual = 0 -> representing perfect predictions; Points above the line -> underprediction; Points below the line -> overprediction\n",
    "4. Line4 - Line6: Adds axis names and proper layout\n",
    "5. Line7: Prevents overlapping elements\n",
    "6. Line8: Displays the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d193bcdf756a2",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d503eb58016ef4f",
   "metadata": {},
   "source": [
    "#### Importing Libraries for Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbb901d609e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from JupiterPycharmProjekt import DataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5089f77bc3062",
   "metadata": {},
   "source": [
    "This code imports the necessary libraries and modules to build and optimize a RandomForest regression model using the prepared dataset.\n",
    "1. Line1: Imports the 'RandomForestRegressor' which combines many decision trees and averages their predictions to improve accuracy and reduce overfitting.\n",
    "2. Line2: Imports 'GridSearchCV' for hyperparameter tuning using cross-validation and 'train_test_split' to split the dataset into training and testing sets.\n",
    "3. Line3: Imports 'DataPrep'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b893978b7e2e4",
   "metadata": {},
   "source": [
    "#### Defining a hyperparameter grid for random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8ea8930060a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7, 8],\n",
    "    'n_estimators': [10, 50, 100, 150, 200],\n",
    "    'criterion': ['squared_error', 'absolute_error']  # [Fix] gültige Kriterien für RandomForestRegressor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee092fc5c8ff8706",
   "metadata": {},
   "source": [
    "This defines a grid of hyperparameters for tuning a 'RandomForestRegressor' using grid search with cross-validation.\n",
    "1. Line1: Defines the maximum depth of each decision tree in the forest\n",
    "2. Line2: Indicates the number of tree's in the random forest\n",
    "3. Line3: Indicates the function used to measure the quality of a split in each tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2648f7947a48a7",
   "metadata": {},
   "source": [
    "#### Train-Test split for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14bac453dccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_RF, X_test_RF, Y_train_RF, Y_test_RF) = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcafe027c2e0d83",
   "metadata": {},
   "source": [
    "This line splits the label-encoded dataset into training and testing subsets for training a Random Forest regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207752869aa7a83",
   "metadata": {},
   "source": [
    "#### Initialize Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afbe9605881465",
   "metadata": {},
   "outputs": [],
   "source": [
    "RForregCV = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5a5db38ce5eae",
   "metadata": {},
   "source": [
    "This line creates a Random Forest Regressor instance with a fixed random seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee0f0e4718c28f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for Random Forest using Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429530d613dc36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfmodel = GridSearchCV(estimator=RForregCV, param_grid=param_grid, cv=4, n_jobs=-1)\n",
    "CV_rfmodel.fit(X_train_RF, Y_train_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdc5c7a3b1c3ec",
   "metadata": {},
   "source": [
    "This block performs automated hyperparameter optimization of a Random Forest model using 4-fold cross-validation on the training data.\n",
    "1. Line1: Creates a GridSearch object to systemically test multiple combinations of hyperparameters for the Random Forest model\n",
    "2. Line2: Executes the grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60c99e6b38c130",
   "metadata": {},
   "source": [
    "#### r2 score calculation for Random Forest on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710ee1fb1f5969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_rfmodel.predict(X_train_RF)\n",
    "Y_train_dev = sum((Y_train_RF - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_RF - Y_train_RF.mean())**2)\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0550bad20008d99",
   "metadata": {},
   "source": [
    "This block manually computes the coefficient of determination for the Random Forest models performance on the training data.\n",
    "1. Line1: Predicts target values using the best fitted Random Forest model on the training set\n",
    "2. Line2: Calculates the sum of squares residuals (SSR) to predict how far values deviate from the actual values.\n",
    "3. Line3: Calculates the total sum of squares (TSS) to measure the total variance in the actual target values.\n",
    "4. Line4: Computes the r2 score which indicates how much of the variance in 'Y_train_RF' is explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778138f8837281e0",
   "metadata": {},
   "source": [
    "#### Evaluate Random Forest Performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564494b502f196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_rfmodel.predict(X_test_RF)\n",
    "Y_test_dev = sum((Y_test_RF - Y_test_pred)**2)\n",
    "Y_test_meandev = sum((Y_test_RF - Y_test_RF.mean())**2)\n",
    "pseudor2 = 1 - Y_test_dev / Y_test_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08b639c614735e",
   "metadata": {},
   "source": [
    "This block computes the pseudo-r2 score for the Random Forest model on the unseen test data.\n",
    "1. Line1: Uses the best model from 'GridSearchCV' to predict the target values for the test set.\n",
    "2. Line2: Calculates the sum of squared errors (residuals) between actual and predicted values on the test set.\n",
    "3. Line3: Computes the total sum of squares (variance) in the actual test targets.\n",
    "4. Line4: Calculates the coefficient of determination on the test set (pseudo-r2) which indicates how well the model explains variance in unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d540ee4aa529b6",
   "metadata": {},
   "source": [
    "#### Logging Random Forest Results and Displaying Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a553fc9304dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"RF_LC \", r2, pseudor2,\"\", CV_rfmodel.cv_results_['mean_test_score'][CV_rfmodel.best_index_], CV_rfmodel.cv_results_['std_test_score'][CV_rfmodel.best_index_]]\n",
    "print(CV_rfmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59b6d0510a8fdb",
   "metadata": {},
   "source": [
    "This block logs the performance of the Random Forest model into a central comparison report and prints the best hyperparameters found during grid search.\n",
    "1. Line1: Appends a new row to the report DataFrame for model comparison\n",
    "2. Line2: Outputs the best combination of hyperparameters found by 'GridSearchCV'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc628866673203",
   "metadata": {},
   "source": [
    "#### Random Forest Training and Evaluation (One-Hot Encoded Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12813474aa89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_RF, X_test_RF, Y_train_RF, Y_test_RF) = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)\n",
    "\n",
    "RForregCV = RandomForestRegressor(random_state=42)\n",
    "\n",
    "CV_rfmodel = GridSearchCV(estimator=RForregCV, param_grid=param_grid, cv=4, n_jobs=-1)\n",
    "CV_rfmodel.fit(X_train_RF, Y_train_RF)\n",
    "\n",
    "Y_train_pred = CV_rfmodel.predict(X_train_RF)\n",
    "Y_train_dev = sum((Y_train_RF - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_RF - Y_train_RF.mean())**2)\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469c5dd6911cd4b",
   "metadata": {},
   "source": [
    "This block trains a Random Forest Regressor on one-hot encoded input features, tunes its hyperparameters with grid search and 4-fold cross-validation and then evaluates the model on the training data using the r2-score.\n",
    "1. Line1: Train-test split with one-hot encoded features\n",
    "2. Line3: Random Forest Model initialization with fixed randomness.\n",
    "3. Line5 - Line6: Hyperparameter tuning using grid-search\n",
    "4. Line8 - Line11: Training set evaluation with r2 score calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84b19404e4640e",
   "metadata": {},
   "source": [
    "#### Evaluate Random Forest Model on Test set (One-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef7d83fcef6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_rfmodel.predict(X_test_RF)\n",
    "Y_test_dev = sum((Y_test_RF - Y_test_pred)**2)\n",
    "Y_test_meandev = sum((Y_test_RF - Y_test_RF.mean())**2)\n",
    "pseudor2 = 1 - Y_test_dev / Y_test_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b1b481b0956b2",
   "metadata": {},
   "source": [
    "This block evaluates how well the tuned Random Forest model performs on unseen test data using a manually calculated pseudo-r2 score.\n",
    "1. Line1: Predicts target values for the test set using the best Random Forest model found by GridSearchCV\n",
    "2. Line2: Calculates the sum of squared errors (SSE)\n",
    "3. Line3: Calculates the total sum of squares (TSS)\n",
    "4. Line4: Computes the pseudo-r2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10251759fdde31d9",
   "metadata": {},
   "source": [
    "#### Logging Random Forest (One-Hot) Results and Displaying Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2d20e4b3020a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"RF_OH \", r2, pseudor2,\"\", CV_rfmodel.cv_results_['mean_test_score'][CV_rfmodel.best_index_], CV_rfmodel.cv_results_['std_test_score'][CV_rfmodel.best_index_]]\n",
    "\n",
    "print(CV_rfmodel.best_params_)\n",
    "print(DataPrep.report.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90a30ac7ec8099",
   "metadata": {},
   "source": [
    "This block finalizes and records the performance results of the Random Forest model trained on one-hot encoded features by appending the results to the 'DataPrep.report', printing the best-found hyperparameters and displaying the top rows of the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3999e7fe0c4d21",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b06bd539d2349",
   "metadata": {},
   "source": [
    "#### Setup for Ridge Regression and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10085119cf7ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.seterr(all='ignore')\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import DataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99cf0b5ca8cda1b",
   "metadata": {},
   "source": [
    "This block imports necessary libraries and suppresses warnings, preparing the environment for Ridge Regression modeling using preprocessed data from 'DataPrep'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da060cffccfe0210",
   "metadata": {},
   "source": [
    "#### Def Grid Serch Plot function (based on Boston Housing PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380578c59cf4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search_1d(cv_results, grid_param, name_param, tital):\n",
    "    plt.plot(grid_param, cv_results['mean_test_score'], '-o')\n",
    "    plt.xlim(1,len(grid_param)-1)\n",
    "    plt.xticks(grid_param)\n",
    "    plt.xlabel(name_param, fontsize=10)\n",
    "    plt.ylabel('CV Average Validation Accuracy', fontsize=10)\n",
    "    #plt.title(\"Grid Search Scores\", fontsize=12, fontweight='bold')\n",
    "    plt.title(tital, fontsize=12, fontweight='bold')\n",
    "    plt.grid('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b0d73d5310d64",
   "metadata": {},
   "source": [
    "This function visualizes the performance results of a 1D grid search, allowing to see how a single hyperparameter affects model performance based on cross-validation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df65680e4f880ec",
   "metadata": {},
   "source": [
    "#### Train-Test Split for Ridge Regression (Label-Encoded Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b263b4f129760",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rig, X_test_rig, Y_train_rig, Y_test_rig = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c18ff62b7ee0d",
   "metadata": {},
   "source": [
    "This line splits the label-encoded dataset into training and testing subsets for training and evaluating a Ridge Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883b8c584fdcd4f",
   "metadata": {},
   "source": [
    "#### Define Ridge Regression function and parameters (penalty parameter alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98480be8f57cbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1,0.5, 1, 2, 3, 5, 10, 25]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d2d4ce6323e2da",
   "metadata": {},
   "source": [
    "This block sets up a Ridge Regression model (Line1) and a grid of alpha values to use in hyperparameter tuning via 'GridSearchCV' (Line2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb44078a6f50bb",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5bb6f9137c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rrmodel = GridSearchCV(estimator=ridge,param_grid=param_grid, cv=10)\n",
    "with np.errstate(over='ignore', divide='ignore', invalid='ignore', under='ignore', all='ignore'):\n",
    "    CV_rrmodel.fit(X_train_rig, Y_train_rig)\n",
    "\n",
    "print(\"Best parameters set values:\", CV_rrmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f2b5ed4027e74",
   "metadata": {},
   "source": [
    "This code performs hyperparameter optimization for a Ridge Regression model using 10-fold cross-validation while supressing numerical warnings during fitting.\n",
    "1. Line1: Performs an exhaustive search over 'param_grid'\n",
    "2. Line2: Temporarily suppresses all numerical warnings during model fitting which ensures a clean output during the fitting process\n",
    "3. Line3: Runs the actual grid search using training data with label-encoded features and evaluates each model and selects the one with the best cross-validation score\n",
    "4. Line5: Outputs the best 'alpha' value found by 'GridSearchCV'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27adc9c4b97d7974",
   "metadata": {},
   "source": [
    "#### Training Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1cbb0e0695ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_rrmodel.predict(X_train_rig)\n",
    "Y_train_dev = sum((Y_train_rig - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_rig - Y_train_rig.mean())**2)  # [aus PDF]\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b8e5c9b0d0a57",
   "metadata": {},
   "source": [
    "This block calculates the coefficient of determination (r2) for the Ridge Regression model on the training data. It shows how well the model fits the data it was trained on.\n",
    "1. Line1: Uses the best Ridge model found by 'GridSearchCV' to make predictions on the training features.\n",
    "2. Line2: Computes the residual sum of squares (SSR) and measures how much the predictions deviate from the actual values.\n",
    "3. Line3: Computes the total sum of squares (TSS) which represents the total variance in target variable.\n",
    "4. Line4: Calculates the r2 score which indicates how well the model explains the variance in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c11c84f585b6",
   "metadata": {},
   "source": [
    "#### Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97862442d8082b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_rrmodel.predict(X_test_rig)\n",
    "Y_test_dev = sum((Y_test_rig - Y_test_pred)**2)\n",
    "Y_train_meandev = sum((Y_test_rig - Y_test_rig.mean())**2)  # [aus PDF]\n",
    "pseudor2 = 1 - Y_test_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdc0859920ebe8",
   "metadata": {},
   "source": [
    "This code computes the pseudo-r2 score for the Ridge Regression model on unseen test data. It evaluates how well the model generalizes beyond the training set.\n",
    "1. Line1: Uses the tuned Ridge model to predict target values on the test dataset.\n",
    "2. Line2: Calculates the sum of squared prediction errors on the test set.\n",
    "3. Line3: Computes the total variance in the actual test values.\n",
    "4. Line4: Calculates the pseudo-r2 and measures how well the model explains the variance in unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409fcc26a3cf907",
   "metadata": {},
   "source": [
    "#### Log Ridge Regression (Label Encoded) Results to Report Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34782627da57293",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = ['Rige RegressionLE', r2, pseudor2,\"\", CV_rrmodel.cv_results_['mean_test_score'][CV_rrmodel.best_index_], CV_rrmodel.cv_results_['std_test_score'][CV_rrmodel.best_index_]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aace7eb09b58b8",
   "metadata": {},
   "source": [
    "This line appends a new row to the model evaluation table 'DataPrep.report' summarizing the performance of the Ridge Regression model trained on label-encoded features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650baa65240f0d7b",
   "metadata": {},
   "source": [
    "#### Residualplot based on Ridge Regression result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7c0bfb913e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y_test_rig - Y_test_pred\n",
    "plt.scatter(Y_test_rig, residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Selling price\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residual plot - Ridge Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307851cc3b8d64d",
   "metadata": {},
   "source": [
    "This block generates a residual plot for the Ridge Regression model on the test dataset showing how prediction errors relate to the actual selling prices.\n",
    "1. Line1: Calculates the residuals: the difference between actual and predicted selling prices\n",
    "2. Line2: Creates a scatter plot\n",
    "3. Line3: Draws a horizontal line at 0 to highlight perfect predictions\n",
    "4. Line4 - Line6: Adds axis labels and title\n",
    "5. Line7 - Line8: Adjusts spacing and displays the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ba1ee3711512d",
   "metadata": {},
   "source": [
    "#### Scatterplot based on Ridge Regression comparing actual and predicted prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b588fae282d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(Y_train_rig, Y_train_pred, alpha=0.5)\n",
    "plt.plot([Y_train_rig.min(), Y_train_rig.max()],\n",
    "         [Y_train_rig.min(), Y_train_rig.max()],\n",
    "         color='red', linestyle='--')  # 45° Reference linie\n",
    "plt.xlabel(\"Actual Selling Price\")\n",
    "plt.ylabel(\"Predicted Selling Price\")\n",
    "plt.title(\"Prediction accuracy - Ridge Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9bce372f00317",
   "metadata": {},
   "source": [
    "This block generates a scatter plot comparing actual vs. predicted values on the training set using the Ridge Regression model.\n",
    "1. Line1: Sets the plot size to 8x5 inches for clarity.\n",
    "2. Line2: Creates the plot\n",
    "3. Line3 - Line5: Adds a 45 degree reference line where ideal predictions would fall along this line; Deviation from this line would indicate prediction errors\n",
    "4. Line6 - Line8: Adds axis labels and title\n",
    "5. Line9 - Line10: Adjusts spacing and displays the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d0b45d753271d5",
   "metadata": {},
   "source": [
    "#### Visualizing Grid Search Results for Ridge Regression (Label Encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b256687c00ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model = CV_rrmodel.cv_results_\n",
    "plt.figure(figsize=(35, 16))\n",
    "param_name = list(param_grid.keys())[0]\n",
    "param_values = param_grid[param_name]\n",
    "plot_grid_search_1d(plot_model, param_values, param_name, tital=\"Grid Search Score LE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b4e6bb2fc785d",
   "metadata": {},
   "source": [
    "This block creates a line plot to visualize the Ridge Regression model's cross-validation performance across different values of the 'alpha' parameter, specifically for label-encoded features.\n",
    "1. Line1: Extracts the full cross-validation results from 'GridSearchCV' after training.\n",
    "2. Line2: Creates a large plot area 35x16 inches for better visibility.\n",
    "3. Line3: Dynamically retrieves the name of the first hyperparameter in 'param_grid' which is 'alpha'\n",
    "4. Line4: Extracts the list of 'alpha' values defined for grid search\n",
    "5. Line5: Calls the previously defined helper function to generate a line plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f8a29a0261051",
   "metadata": {},
   "source": [
    "#### Train-Test Split for Ridge Regression (One-hot Encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49205a3580e6afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rig, X_test_rig, Y_train_rig, Y_test_rig = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e1cad95999a9f",
   "metadata": {},
   "source": [
    "This line splits the One-Hot encoded dataset into training and testing sets for use in Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab004f33f14ad1",
   "metadata": {},
   "source": [
    "#### Ridge Regression Setup with Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6606b926bde40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1,0.5, 1, 2, 3, 5, 10, 25]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3731eedc288390aa",
   "metadata": {},
   "source": [
    "This code sets up a ridge regression model instance and a grid of alpha values to test during hyperparameter tuning using 'GridSearchCV'\n",
    "1. Line1: Initializes a Ridge Regression model with default parameters\n",
    "2. Line2: Defines a range of values for the 'alpha' hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa40b6c1d1303b6",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cddd5a9c83c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rrmodel = GridSearchCV(estimator=ridge,param_grid=param_grid, cv=10)\n",
    "with np.errstate(over='ignore', divide='ignore', invalid='ignore', under='ignore', all='ignore'):\n",
    "    CV_rrmodel.fit(X_train_rig, Y_train_rig)\n",
    "\n",
    "print(\"Best parameters set values:\", CV_rrmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa152e63e3c98ac",
   "metadata": {},
   "source": [
    "This code performs a grid search with cross-validation to find the optimal 'alpha' for a Ridge Regression model using One-Hot encoded data, while suppressing any numerical warnings.\n",
    "1. Line1: Initializes grid search to find the best 'alpha' for Ridge Regression.\n",
    "2. Line2: Temporarily suppresses numerical warnings to ensure clean output.\n",
    "3. Line3: Trains Ridge Regression models using all combinations from the parameter grid, evaluates performance using cross-validation and stores the best performing model.\n",
    "4. Line5: Outputs the 'alpha' value that gave the best average validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3917400ac6501a4c",
   "metadata": {},
   "source": [
    "#### Evaluate Ridge Regression Performance on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eddcb2e0beaf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_rrmodel.predict(X_train_rig)\n",
    "Y_train_dev = sum((Y_train_rig - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_rig - Y_train_rig.mean())**2)  # [aus PDF]\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b98cf8f79a8777",
   "metadata": {},
   "source": [
    "This block calculates the r2 score of the Ridge Regression model on the training data, which was One-Hot encoded.\n",
    "1. Line1: Uses the best model found via GridSearchCV to predict selling prices for the training set.\n",
    "2. Line2: Computes the residual sum of squares (RSS).\n",
    "3. Line3: Computes the total sum of squares (TSS).\n",
    "4. Line4: Calculates the r2 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162264436b17fdea",
   "metadata": {},
   "source": [
    "#### Evaluate Ridge Regression Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0572fe62026ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_rrmodel.predict(X_test_rig)\n",
    "Y_test_dev = sum((Y_test_rig - Y_test_pred)**2)\n",
    "Y_train_meandev = sum((Y_test_rig - Y_test_rig.mean())**2)  # [aus PDF]\n",
    "pseudor2 = 1 - Y_test_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff531e56b05ba1c",
   "metadata": {},
   "source": [
    "1. Line1: Uses the best model found via GridSearchCV to predict selling prices for the test set.\n",
    "2. Line2: Computes the residual sum of squares (RSS).\n",
    "3. Line3: Computes the total sum of squares (TSS).\n",
    "4. Line4: Calculates the r2 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8775c99ea432bf",
   "metadata": {},
   "source": [
    "#### Log Ridge Regression Results into Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1de70cbfef871",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"Rige RegressionOH \", r2, pseudor2,\"\", CV_rrmodel.cv_results_['mean_test_score'][CV_rrmodel.best_index_], CV_rrmodel.cv_results_['std_test_score'][CV_rrmodel.best_index_]]\n",
    "\n",
    "print(DataPrep.report.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3de6f7350be49",
   "metadata": {},
   "source": [
    "This code adds a new row to the model comparison table 'DataPrep.report', summarizing the performance of Ridge Regression using One-Hot encoded features. It then prints the first few entries of the report for review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cde61011b68fc9",
   "metadata": {},
   "source": [
    "#### Residual Plot based on Ridge Regression result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5106c872b09859",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = Y_test_rig - Y_test_pred\n",
    "plt.scatter(Y_test_rig, residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Selling price\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.title(\"Residual plot - Ridge Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3832d7b094f86d",
   "metadata": {},
   "source": [
    "This block generates a residual plot for the Ridge Regression model evaluated on the test set using One-Hot encoded features. It shows how far off each prediction is from the actual value.\n",
    "1. Line1: Calculates the residuals for each test sample\n",
    "2. Line2: Plotter a scatter diagram\n",
    "3. Line3: Draws a red dashed horizontal reference line at 0 - representing perfect prediction\n",
    "4. Line4 - Line6: Adds axis labels and title\n",
    "5. Line7 - Line8: Ensures no layout overlap and displays final plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef27c93c70ecb",
   "metadata": {},
   "source": [
    "#### Scatterplot based on Ridge Regression comparing actual and predicted prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dce54ad0f91fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(Y_train_rig, Y_train_pred, alpha=0.5)\n",
    "plt.plot([Y_train_rig.min(), Y_train_rig.max()],\n",
    "         [Y_train_rig.min(), Y_train_rig.max()],\n",
    "         color='red', linestyle='--')  # 45° Reference linie\n",
    "plt.xlabel(\"Actual Selling Price\")\n",
    "plt.ylabel(\"Predicted Selling Price\")\n",
    "plt.title(\"Prediction accuracy - Ridge Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b31211520fdcf",
   "metadata": {},
   "source": [
    "This block generates a scatter plot comparing predicted vs. actual values on the training set for the Ridge Regression model using One-Hot encoded features.\n",
    "1. Line1: Sets the plot size to 8 inches wide and 5 inches tall.\n",
    "2. Line2: Plots a scatterplot.\n",
    "3. Line3: Draws a red dashed 45 degree reference line which represents perfect predictions. The closer the points are to this line, the better the model's predictions.\n",
    "4. Line6 - Line8: Adds axis labels and title\n",
    "5. Line9 - Line10: Ensures the layout is clean and then displays the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a89aebe7ff6ad5",
   "metadata": {},
   "source": [
    "#### Visualizing Grid Search Results for Ridge Regression (One-hot Encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec93560cee0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model = CV_rrmodel.cv_results_\n",
    "plt.figure(figsize=(35, 16))\n",
    "param_name = list(param_grid.keys())[0]\n",
    "param_values = param_grid[param_name]\n",
    "plot_grid_search_1d(plot_model, param_values, param_name, tital=\"Grid Search Score OH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345d784557191a3",
   "metadata": {},
   "source": [
    "This block creates a line plot that visualizes how the Ridge Regression model's cross-validation performance changes with different values of the hyperparameter 'alpha'.\n",
    "1. Line1: Extracts detailed cross-validation results from the 'GridSearchCV' object.\n",
    "2. Line2: Sets the size of the figure.\n",
    "3. Line3: Extracts the name of the hyperparameter being tuned.\n",
    "4. Line4: Retrieves the list of 'alpha' values used in grid search.\n",
    "5. Line5: Calls the plotting function to plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387284e31ccce72",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a94da0801c419",
   "metadata": {},
   "source": [
    "#### Import Libraries for SVR Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9327198a3dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from JupiterPycharmProjekt import DataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c01862fbfa59b",
   "metadata": {},
   "source": [
    "This block imports all the necessary libraries and modules to prepare and train a Support Vector Regression (SVR) model for predicting used car selling prices, as well as for plotting and data management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5c661e593ff39",
   "metadata": {},
   "source": [
    "#### Train-Test Split for SVR using Label Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8568512955c31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_svr, X_test_svr, Y_train_svr, Y_test_svr) = train_test_split(DataPrep.X_LE, DataPrep.Y_LE, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862f04e1abc9d9a1",
   "metadata": {},
   "source": [
    "This line splits the label-encoded dataset into training and testing sets to prepare for Support Vector Regression (SVR) model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6ffaeab8d9b19",
   "metadata": {},
   "source": [
    "#### Hyperparameter Grid for SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaec1e5ffed9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "'kernel': [\"linear\", \"rbf\"],\n",
    "'C': [1, 3, 5, 8, 10],\n",
    "'epsilon': [0.0, 0.025, 0.05, 0.075, 0.1],\n",
    "'gamma': [0., 1., 2., 3., 4.]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49990531e0484a9",
   "metadata": {},
   "source": [
    "This block defines a grid of hyperparameters for use in 'GridSearchCV', allowing the model to test different combinations of settings for Support Vector Regression (SVR). The goal is to find the combination that yields the best predictive performance.\n",
    "1. Line2: Controls how SVR maps input data into higher dimensions. \"rbf\" allows for non-linear regression, while \"linear\" fits a straight hyperplane.\n",
    "2. Line3: Regularization parameter (penalty for error)\n",
    "3. Line4: Controls the model’s sensitivity to small errors. Larger epsilon allows more tolerance in error without penalty.\n",
    "4. Line5: Controls the influence of a single training point. High gamma -> more complex models, low gamma -> smoother models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42dd50952a9f09",
   "metadata": {},
   "source": [
    "#### Train SVR with Grid Search and Kernel Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596251ead86bda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVRreg = SVR()\n",
    "CV_svrmodel = GridSearchCV(estimator=LinSVRreg, param_grid=param_grid, cv=4,n_jobs=-1)\n",
    "CV_svrmodel.fit(X_train_svr, Y_train_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8157e42e0462a",
   "metadata": {},
   "source": [
    "This block sets up and trains a Support Vector Regression (SVR) model using Grid Search to find the best combination of hyperparameters, including the kernel type. It runs 4-fold cross-validation and uses all available CPU cores to speed up the process.\n",
    "1. Line1: Creates a default SVR model.\n",
    "2. Line2: Automatically tests all combinations of parameters in 'param_grid' using cross-validation.\n",
    "3. Line3: Fits all model combinations using the training data, evaluates each combination using 4-fold CV and stores the best model based on validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8ea5ee6c87ca4",
   "metadata": {},
   "source": [
    "#### Evaluate SVR Model Performance on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f9f7ebf5290e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_svrmodel.predict(X_train_svr)\n",
    "Y_train_dev = sum((Y_train_svr - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_svr - Y_train_svr.mean())**2)  # [aus PDF]\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4c5c2f17cf602",
   "metadata": {},
   "source": [
    "This code evaluates the performance of the best SVR model (from GridSearchCV) on the training dataset using the coefficient of determination (r2), a standard metric for regression.\n",
    "1. Line1: Uses the trained SVR model to predict selling prices for the training set\n",
    "2. Line2: Calculates the Residual Sum of Squares (RSS) which represents the total prediction error\n",
    "3. Line3: Calculates the Total Sum of Squares (TSS) which measures the total variance in the actual target values\n",
    "4. Line4: Computes the r2 score, also called the coefficient of determination which indicates how much variance is explained by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9fb5d2065cfd0",
   "metadata": {},
   "source": [
    "#### Evaluate SVR Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a25fda372f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_svrmodel.predict(X_test_svr)\n",
    "Y_test_dev = sum((Y_test_svr - Y_test_pred)**2)\n",
    "Y_train_meandev = sum((Y_test_svr - Y_test_svr.mean())**2)  # [aus PDF]\n",
    "pseudor2 = 1 - Y_test_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75622507df1679ba",
   "metadata": {},
   "source": [
    "This code computes the r2 score on the test set (often called pseudo-r2) to evaluate how well the trained Support Vector Regression (SVR) model generalizes to unseen data.\n",
    "1. Line1: Predicts selling prices for the test set using the best SVR model from 'GridSearchCV'\n",
    "2. Line2: Calculates the sum of squared errors (RSS) between the actual and predicted values on the test set\n",
    "3. Line3: Computes the total variance (TSS) in the actual test values\n",
    "4. Line4: Computes the pseudo-r2 score which measures how well the model explains variance in unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd4970ec32236d",
   "metadata": {},
   "source": [
    "#### Log SVR Results into Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d1fdb13af716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"SVRLE \", r2, pseudor2,\"\", CV_svrmodel.cv_results_['mean_test_score'][CV_svrmodel.best_index_], CV_svrmodel.cv_results_['std_test_score'][CV_svrmodel.best_index_]]\n",
    "print(CV_svrmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f2d158e81e255",
   "metadata": {},
   "source": [
    "This block records the Support Vector Regression (SVR) model’s performance into a central report DataFrame. It then prints the best hyperparameters found during the grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bef92559b6a9a",
   "metadata": {},
   "source": [
    "#### Extract Grid Search Results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633234fb147fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(CV_svrmodel.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b290a4662e6476",
   "metadata": {},
   "source": [
    "This line converts the full cross-validation results from 'GridSearchCV' into a Pandas DataFrame for easy inspection, filtering, and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b193e4da6f22db2",
   "metadata": {},
   "source": [
    "#### Filter Grid Search Results for Best SVR Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08756eee30d0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = CV_svrmodel.best_params_\n",
    "filtered = cv_results_df[\n",
    "(cv_results_df['param_C'] == best_params['C']) &\n",
    "(cv_results_df['param_epsilon'] == best_params['epsilon']) &\n",
    "(cv_results_df['param_kernel'] == best_params['kernel'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bed074734537ec",
   "metadata": {},
   "source": [
    "This block filters the full grid search results to only include rows where the hyperparameters match the best model, except for 'gamma', which is intentionally left unconstrained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ceaefe7a7ef5a",
   "metadata": {},
   "source": [
    "#### Sort filtered GridSearch Results by 'gamma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea3750ee082b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filtered.sort_values(by='param_gamma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b323f5b35e61bb",
   "metadata": {},
   "source": [
    "This line sorts the previously filtered cross-validation results in ascending order of the 'gamma' parameter. It prepares the data for plotting trends or analyzing the impact of 'gamma' on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ca232c2b41e07",
   "metadata": {},
   "source": [
    "#### SVR model performance under 'gamma' influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a571f61ee0ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(filtered['param_gamma'], filtered['mean_test_score'], marker='o')\n",
    "plt.fill_between(filtered['param_gamma'],\n",
    "filtered['mean_test_score'] - filtered['std_test_score'],\n",
    "filtered['mean_test_score'] + filtered['std_test_score'],\n",
    "alpha=0.2)\n",
    "plt.title(\"SVR Cross-Validation Score vs Gamma (RBF Kernel) LE\", fontsize=14)\n",
    "plt.xlabel(\"Gamma\", fontsize=12)\n",
    "plt.ylabel(\"Mean CV Score\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(filtered['param_gamma'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f1bc28e572800",
   "metadata": {},
   "source": [
    "This block visualizes how the 'gamma' parameter affects SVR model performance (measured by cross-validation score) while keeping other parameters fixed ('C', 'epsilon', 'kernel' = best values). It’s specific to models using the RBF kernel and Label Encoded features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897a7239263aa48",
   "metadata": {},
   "source": [
    "####  Filter Grid Search Results to Analyze 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1067a7e3ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_C = cv_results_df[\n",
    "(cv_results_df['param_gamma'] == best_params['gamma']) &\n",
    "(cv_results_df['param_epsilon'] == best_params['epsilon']) &\n",
    "(cv_results_df['param_kernel'] == best_params['kernel'])\n",
    "].sort_values(by='param_C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea95cbe35ecf3b2",
   "metadata": {},
   "source": [
    "This block filters the full set of SVR cross-validation results to only include rows where:\n",
    "1. 'gamma' is fixed to its best-found value\n",
    "2. 'epsilon' is fixed to its best-found value\n",
    "3. 'kernel' is fixed to its best-found value (e.g., \"rbf\")\n",
    "\n",
    "Then it sorts the filtered data by the regularization parameter 'C', so you can analyze how changing 'C' affects performance while keeping other key parameters constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c4734034a6e12",
   "metadata": {},
   "source": [
    "#### SVR model performance under 'C' influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179314194bb6caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(filtered_C['param_C'], filtered_C['mean_test_score'], marker='o')\n",
    "plt.fill_between(filtered_C['param_C'],\n",
    "filtered_C['mean_test_score'] - filtered_C['std_test_score'],\n",
    "filtered_C['mean_test_score'] + filtered_C['std_test_score'],\n",
    "alpha=0.2)\n",
    "plt.title(\"SVR Cross-Validation Score vs C (RBF Kernel) LE\", fontsize=14)\n",
    "plt.xlabel(\"C\", fontsize=12)\n",
    "plt.ylabel(\"Mean CV Score\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(filtered_C['param_C'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d06503722a99a4",
   "metadata": {},
   "source": [
    "This code visualizes how the SVR model’s cross-validation performance varies with different values of 'C' (the regularization parameter), while keeping 'gamma', 'epsilon', and 'kernel' fixed at their best values — using Label Encoded features and the RBF kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64778533489ba4e",
   "metadata": {},
   "source": [
    "#### Filter Grid Search Results to Analyze the Effect of 'epsilon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2ab2ce9a3d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_eps = cv_results_df[\n",
    "(cv_results_df['param_gamma'] == best_params['gamma']) &\n",
    "(cv_results_df['param_C'] == best_params['C']) &\n",
    "(cv_results_df['param_kernel'] == best_params['kernel'])\n",
    "].sort_values(by='param_epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31670fdb829bbc2",
   "metadata": {},
   "source": [
    "This code filters the cross-validation results to isolate the effect of the 'epsilon' parameter in Support Vector Regression (SVR), while fixing the other key parameters ('C', 'gamma', and 'kernel') to their optimal values as determined by GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c6237de2bcae5",
   "metadata": {},
   "source": [
    "#### SVR model performance under 'epsilon' influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619af610eb0e3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(filtered_eps['param_epsilon'], filtered_eps['mean_test_score'], marker='o')\n",
    "plt.fill_between(filtered_eps['param_epsilon'],\n",
    "filtered_eps['mean_test_score'] - filtered_eps['std_test_score'],\n",
    "filtered_eps['mean_test_score'] + filtered_eps['std_test_score'],\n",
    "alpha=0.2)\n",
    "plt.title(\"SVR Cross-Validation Score vs Epsilon (RBF Kernel) LE\", fontsize=14)\n",
    "plt.xlabel(\"Epsilon\", fontsize=12)\n",
    "plt.ylabel(\"Mean CV Score\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(filtered_eps['param_epsilon'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7689b4456ff42134",
   "metadata": {},
   "source": [
    "This code visualizes how the Support Vector Regression (SVR) model's performance varies with different values of 'epsilon', using:\n",
    "1. The RBF kernel\n",
    "2. Label Encoded input data\n",
    "3. Fixed values for 'C', 'gamma', and 'kernel' (as selected by GridSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7a0c46d4a152a",
   "metadata": {},
   "source": [
    "#### Train-Test Split for SVR Using One-Hot Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d036ac3a12f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_svr, X_test_svr, Y_train_svr, Y_test_svr) = train_test_split(DataPrep.X_OH, DataPrep.Y_OH, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796bd976efdb2dc8",
   "metadata": {},
   "source": [
    "This line splits the dataset into training and test sets for a Support Vector Regression (SVR) model using One-Hot Encoded features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1754876df6b926d",
   "metadata": {},
   "source": [
    "#### Train SVR with Grid Search (One-Hot Encoded Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef72b89485d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVRreg = SVR()\n",
    "CV_svrmodel = GridSearchCV(estimator=LinSVRreg, param_grid=param_grid, cv=4,n_jobs=-1)\n",
    "CV_svrmodel.fit(X_train_svr, Y_train_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b880030d454140",
   "metadata": {},
   "source": [
    "This block sets up and trains a Support Vector Regression (SVR) model using One-Hot Encoded features, with automated hyperparameter tuning via GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb1d556659464da",
   "metadata": {},
   "source": [
    "#### Evaluate SVR Performance on Training Data (r2 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc575a223269bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = CV_svrmodel.predict(X_train_svr)\n",
    "Y_train_dev = sum((Y_train_svr - Y_train_pred)**2)\n",
    "Y_train_meandev = sum((Y_train_svr - Y_train_svr.mean())**2)  # [aus PDF]\n",
    "r2 = 1 - Y_train_dev / Y_train_meandev  # [aus PDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abd74fd7ff1403",
   "metadata": {},
   "source": [
    "This block computes the r2 (coefficient of determination) on the training dataset for the Support Vector Regression (SVR) model trained using One-Hot Encoded data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b69d720b5a0787",
   "metadata": {},
   "source": [
    "#### Evaluate SVR Performance on Test Data (pseudo-r2 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88415015034d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = CV_svrmodel.predict(X_test_svr)\n",
    "Y_test_dev = sum((Y_test_svr - Y_test_pred)**2)\n",
    "Y_train_meandev = sum((Y_test_svr - Y_test_svr.mean())**2)  # [aus PDF]\n",
    "pseudor2 = 1 - Y_test_dev / Y_train_meandev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95d7fdb187210",
   "metadata": {},
   "source": [
    "This block calculates the \"pseudo r2\" score — a performance measure of the SVR model on unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c4f9bc5c6e9d1",
   "metadata": {},
   "source": [
    "#### Log SVR model results into report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0e2d91c2a9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPrep.report.loc[len(DataPrep.report)] = [\"SVROH \", r2, pseudor2,\"\", CV_svrmodel.cv_results_['mean_test_score'][CV_svrmodel.best_index_], CV_svrmodel.cv_results_['std_test_score'][CV_svrmodel.best_index_]]\n",
    "print(DataPrep.report.head())\n",
    "print(CV_svrmodel.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27336d3eb623b9",
   "metadata": {},
   "source": [
    "Appends a new row to the shared report DataFrame from the DataPrep module.\n",
    "Stores performance results of the SVR model trained using One-Hot Encoded features.\n",
    "Displays the current top rows of the report and the best hyperparameters found during GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd823d8dd5324d7",
   "metadata": {},
   "source": [
    "#### Convert Grid Search Results to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31e507e1c6424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(CV_svrmodel.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2801eb3c340ec9",
   "metadata": {},
   "source": [
    "This line converts the full cross-validation results from 'GridSearchCV' into a Pandas DataFrame called 'cv_results_df'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b616e65cc3c85",
   "metadata": {},
   "source": [
    "#### Filter Grid Search Results Using Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8bd031f929d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = CV_svrmodel.best_params_\n",
    "filtered = cv_results_df[\n",
    "(cv_results_df['param_C'] == best_params['C']) &\n",
    "(cv_results_df['param_epsilon'] == best_params['epsilon']) &\n",
    "(cv_results_df['param_kernel'] == best_params['kernel'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a5791d7faa287",
   "metadata": {},
   "source": [
    "This block filters the full cross-validation results ('cv_results_df') to create a subset called 'filtered', which contains only the rows where 'C' is equal to the best value found during grid search, 'epsilon' is equal to the best epsilon and 'kernel' is the best-performing kernel (typically 'rbf' or 'linear')\n",
    "This filtered dataset is useful for analyzing the effect of other parameters while holding these three constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b88d9fedb02039b",
   "metadata": {},
   "source": [
    "#### Sort Filtered Grid Search Results by 'gamma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b71772662d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filtered.sort_values(by='param_gamma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee347505b5e838",
   "metadata": {},
   "source": [
    "This line sorts the previously filtered DataFrame (which contains only rows with the best values for 'C', 'epsilon', and 'kernel') by the hyperparameter 'gamma', in ascending order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52becdd30bdf1d4a",
   "metadata": {},
   "source": [
    "#### SVR model performance under 'gamma' influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87f661ba96ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(filtered['param_gamma'], filtered['mean_test_score'], marker='o')\n",
    "plt.fill_between(filtered['param_gamma'],\n",
    "filtered['mean_test_score'] - filtered['std_test_score'],\n",
    "filtered['mean_test_score'] + filtered['std_test_score'],\n",
    "alpha=0.2)\n",
    "plt.title(\"SVR Cross-Validation Score vs Gamma (RBF Kernel) OH\", fontsize=14)\n",
    "plt.xlabel(\"Gamma\", fontsize=12)\n",
    "plt.ylabel(\"Mean CV Score\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(filtered['param_gamma'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731cce007c39b9cc",
   "metadata": {},
   "source": [
    "This plot visualizes how the mean cross-validation score for a Support Vector Regression (SVR) model changes with different values of 'gamma', while keeping:\n",
    "1. 'C' (regularization)\n",
    "2. 'epsilon' (error margin)\n",
    "3. 'kernel' ('rbf')\n",
    "\n",
    "fixed at their best values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32efcab593a7528",
   "metadata": {},
   "source": [
    "#### Filter CV Results to Analyze 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd75c0c9829a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_C = cv_results_df[\n",
    "(cv_results_df['param_gamma'] == best_params['gamma']) &\n",
    "(cv_results_df['param_epsilon'] == best_params['epsilon']) &\n",
    "(cv_results_df['param_kernel'] == best_params['kernel'])\n",
    "].sort_values(by='param_C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea82c0f9d58888f",
   "metadata": {},
   "source": [
    "This code filters the cross-validation results DataFrame ('cv_results_df') to include only those rows where:\n",
    "1. 'gamma' matches the best-performing value from GridSearchCV\n",
    "2. 'epsilon' matches the best value\n",
    "3. 'kernel' (e.g., 'rbf') is the best one used\n",
    "\n",
    "It then sorts the filtered results by the hyperparameter 'C' (the regularization strength)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5ea44f6220102",
   "metadata": {},
   "source": [
    "#### SVR model performance under 'C' influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68046a18e2f741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(filtered_C['param_C'], filtered_C['mean_test_score'], marker='o')\n",
    "plt.fill_between(filtered_C['param_C'],\n",
    "filtered_C['mean_test_score'] - filtered_C['std_test_score'],\n",
    "filtered_C['mean_test_score'] + filtered_C['std_test_score'],\n",
    "alpha=0.2)\n",
    "plt.title(\"SVR Cross-Validation Score vs C (RBF Kernel) OH\", fontsize=14)\n",
    "plt.xlabel(\"C\", fontsize=12)\n",
    "plt.ylabel(\"Mean CV Score\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(filtered_C['param_C'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631e3395a246e9b",
   "metadata": {},
   "source": [
    "This plot visualizes how the mean cross-validation score changes for different values of the regularization parameter 'C', while holding the best values of the other hyperparameters constant:\n",
    "1. 'gamma' = best value\n",
    "2. 'epsilon' = best value\n",
    "3. 'kernel' = 'rbf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7c7431af966af",
   "metadata": {},
   "source": [
    "#### Filter CV Results to Analyze 'epsilon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185aae251422b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_eps = cv_results_df[\n",
    "(cv_results_df['param_gamma'] == best_params['gamma']) &\n",
    "(cv_results_df['param_C'] == best_params['C']) &\n",
    "(cv_results_df['param_kernel'] == best_params['kernel'])\n",
    "].sort_values(by='param_epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3440528b189f887",
   "metadata": {},
   "source": [
    "This block filters the full cross-validation results ('cv_results_df') to only include configurations where:\n",
    "1. 'gamma' is fixed to the best-performing value\n",
    "2. 'C' is fixed to the best value\n",
    "3. 'kernel' is the best-performing kernel (usually 'rbf')\n",
    "\n",
    "Then, it sorts the remaining rows by 'epsilon', preparing the data to analyze how 'epsilon' affects model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a0a41b26de307",
   "metadata": {},
   "source": [
    "#### SVR model performance under 'epsilon' influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49143f26897efb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(filtered_eps['param_epsilon'], filtered_eps['mean_test_score'], marker='o')\n",
    "plt.fill_between(filtered_eps['param_epsilon'],\n",
    "filtered_eps['mean_test_score'] - filtered_eps['std_test_score'],\n",
    "filtered_eps['mean_test_score'] + filtered_eps['std_test_score'],\n",
    "alpha=0.2)\n",
    "plt.title(\"SVR Cross-Validation Score vs Epsilon (RBF Kernel) OH\", fontsize=14)\n",
    "plt.xlabel(\"Epsilon\", fontsize=12)\n",
    "plt.ylabel(\"Mean CV Score\", fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(filtered_eps['param_epsilon'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054cdab9f62cc4c",
   "metadata": {},
   "source": [
    "This visualization demonstrates how the SVR model's performance (measured by cross-validation score) changes with different values of 'epsilon', while keeping the following hyperparameters fixed at their optimal values:\n",
    "1. 'C' = best value\n",
    "2. 'gamma' = best value\n",
    "3. 'kernel' = 'rbf' (radial basis function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
